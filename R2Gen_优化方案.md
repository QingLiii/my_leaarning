# R2Gen æ·±åº¦ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“‹ ä¼˜åŒ–ç›®æ ‡
1. **WandBç›‘æ§é›†æˆ** - å…¨é¢ç›‘æ§è®­ç»ƒè¿‡ç¨‹å’Œç¡¬ä»¶æ€§èƒ½
2. **æ˜¾å­˜ä¼˜åŒ–** - åŠ¨æ€è°ƒæ•´batch sizeå’Œæ¢¯åº¦ç´¯ç§¯
3. **ç²¾åº¦å®éªŒ** - å¯¹æ¯”FP32ã€FP16ã€FP8çš„æ€§èƒ½å’Œæ•ˆæœ

## ğŸ¯ å®æ–½è®¡åˆ’

### é˜¶æ®µä¸€ï¼šWandBç›‘æ§ç³»ç»Ÿé›†æˆ

#### 1.1 åˆ›å»ºWandBé…ç½®æ¨¡å—
```python
# modules/wandb_logger.py
import wandb
import torch
import psutil
import GPUtil
import time
from typing import Dict, Any

class WandBLogger:
    def __init__(self, project_name="R2Gen-Optimization", api_key="68c9ce2a167992d06678c4fdc0d1075b5dfff922"):
        wandb.login(key=api_key)
        self.project_name = project_name
        
    def init_run(self, config: Dict[str, Any], run_name: str = None):
        wandb.init(
            project=self.project_name,
            config=config,
            name=run_name,
            tags=["optimization", "precision_study"]
        )
        
    def log_system_metrics(self):
        """è®°å½•ç³»ç»Ÿå’ŒGPUæ€§èƒ½æŒ‡æ ‡"""
        # CPUå’Œå†…å­˜
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        
        # GPUä¿¡æ¯
        gpus = GPUtil.getGPUs()
        gpu_metrics = {}
        for i, gpu in enumerate(gpus):
            gpu_metrics[f'gpu_{i}_utilization'] = gpu.load * 100
            gpu_metrics[f'gpu_{i}_memory_used'] = gpu.memoryUsed
            gpu_metrics[f'gpu_{i}_memory_total'] = gpu.memoryTotal
            gpu_metrics[f'gpu_{i}_memory_percent'] = (gpu.memoryUsed / gpu.memoryTotal) * 100
            gpu_metrics[f'gpu_{i}_temperature'] = gpu.temperature
        
        wandb.log({
            'system/cpu_percent': cpu_percent,
            'system/memory_percent': memory.percent,
            'system/memory_used_gb': memory.used / (1024**3),
            **gpu_metrics
        })
```

#### 1.2 å¢å¼ºTrainerç±»
```python
# åœ¨trainer.pyä¸­æ·»åŠ WandBé›†æˆ
class EnhancedTrainer(BaseTrainer):
    def __init__(self, model, criterion, metric_ftns, optimizer, args, lr_scheduler, 
                 train_dataloader, val_dataloader, test_dataloader, wandb_logger=None):
        super().__init__(model, criterion, metric_ftns, optimizer, args)
        self.wandb_logger = wandb_logger
        self.gradient_accumulation_steps = getattr(args, 'gradient_accumulation_steps', 1)
        self.mixed_precision = getattr(args, 'mixed_precision', None)  # 'fp16', 'fp8', None
        
        # åˆå§‹åŒ–æ··åˆç²¾åº¦
        if self.mixed_precision == 'fp16':
            self.scaler = torch.cuda.amp.GradScaler()
        
    def _train_epoch(self, epoch):
        train_loss = 0
        self.model.train()
        
        for batch_idx, (images_id, images, reports_ids, reports_masks) in enumerate(self.train_dataloader):
            # ç³»ç»Ÿç›‘æ§
            if batch_idx % 10 == 0 and self.wandb_logger:
                self.wandb_logger.log_system_metrics()
            
            # å‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®—
            loss = self._forward_step(images, reports_ids, reports_masks)
            
            # æ¢¯åº¦ç´¯ç§¯
            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
                self._backward_step(loss)
                
            train_loss += loss.item()
            
            # è®°å½•è®­ç»ƒæŒ‡æ ‡
            if self.wandb_logger and batch_idx % 50 == 0:
                wandb.log({
                    'train/batch_loss': loss.item(),
                    'train/learning_rate': self.optimizer.param_groups[0]['lr'],
                    'train/epoch': epoch,
                    'train/batch': batch_idx
                })
        
        return {'train_loss': train_loss / len(self.train_dataloader)}
```

### é˜¶æ®µäºŒï¼šæ˜¾å­˜ä¼˜åŒ–å’ŒåŠ¨æ€Batch Size

#### 2.1 æ˜¾å­˜ç›‘æ§å’Œè‡ªé€‚åº”Batch Size
```python
# modules/memory_optimizer.py
import torch
import GPUtil

class MemoryOptimizer:
    def __init__(self, initial_batch_size=16, max_memory_percent=85):
        self.initial_batch_size = initial_batch_size
        self.current_batch_size = initial_batch_size
        self.max_memory_percent = max_memory_percent
        self.gradient_accumulation_steps = 1
        
    def get_gpu_memory_usage(self):
        """è·å–GPUæ˜¾å­˜ä½¿ç”¨ç‡"""
        gpus = GPUtil.getGPUs()
        if gpus:
            return (gpus[0].memoryUsed / gpus[0].memoryTotal) * 100
        return 0
    
    def optimize_batch_size(self, model, sample_batch):
        """åŠ¨æ€ä¼˜åŒ–batch size"""
        print("ğŸ” å¼€å§‹æ˜¾å­˜ä¼˜åŒ–æµ‹è¯•...")
        
        # æµ‹è¯•ä¸åŒbatch sizeçš„æ˜¾å­˜ä½¿ç”¨
        test_sizes = [4, 8, 16, 24, 32, 48, 64]
        optimal_size = self.initial_batch_size
        
        for size in test_sizes:
            try:
                # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
                test_batch = self._create_test_batch(sample_batch, size)
                
                torch.cuda.empty_cache()
                memory_before = self.get_gpu_memory_usage()
                
                with torch.no_grad():
                    _ = model(*test_batch)
                
                memory_after = self.get_gpu_memory_usage()
                
                print(f"Batch size {size}: {memory_after:.1f}% GPU memory")
                
                if memory_after < self.max_memory_percent:
                    optimal_size = size
                else:
                    break
                    
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"OOM at batch size {size}")
                    break
                    
        # è®¡ç®—æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        target_effective_batch = self.initial_batch_size
        self.current_batch_size = optimal_size
        self.gradient_accumulation_steps = max(1, target_effective_batch // optimal_size)
        
        print(f"âœ… ä¼˜åŒ–ç»“æœ: batch_size={optimal_size}, gradient_accumulation={self.gradient_accumulation_steps}")
        return optimal_size, self.gradient_accumulation_steps
```

### é˜¶æ®µä¸‰ï¼šç²¾åº¦å¯¹æ¯”å®éªŒ

#### 3.1 ç²¾åº¦å®éªŒé…ç½®
```python
# experiments/precision_study.py
import torch
from torch.cuda.amp import autocast, GradScaler

class PrecisionExperiment:
    def __init__(self, base_args):
        self.base_args = base_args
        self.precision_configs = {
            'fp32': {'mixed_precision': None, 'description': 'Full Precision'},
            'fp16': {'mixed_precision': 'fp16', 'description': 'Half Precision'},
            'fp8': {'mixed_precision': 'fp8', 'description': 'FP8 Precision (if supported)'}
        }
        
    def run_precision_study(self):
        """è¿è¡Œç²¾åº¦å¯¹æ¯”å®éªŒ"""
        results = {}
        
        for precision_name, config in self.precision_configs.items():
            print(f"\nğŸ§ª å¼€å§‹ {precision_name} ç²¾åº¦å®éªŒ...")
            
            # åˆ›å»ºå®éªŒé…ç½®
            exp_args = self._create_experiment_args(precision_name, config)
            
            # è¿è¡Œå®éªŒ
            result = self._run_single_experiment(exp_args, precision_name)
            results[precision_name] = result
            
        return results
    
    def _create_experiment_args(self, precision_name, config):
        """åˆ›å»ºå®éªŒå‚æ•°"""
        import copy
        args = copy.deepcopy(self.base_args)
        
        # è®¾ç½®å®éªŒç‰¹å®šå‚æ•°
        args.epochs = 15
        args.save_dir = f"results/precision_study/{precision_name}"
        args.mixed_precision = config['mixed_precision']
        args.experiment_name = f"R2Gen_{precision_name}_precision"
        
        return args
```

#### 3.2 å®éªŒæ‰§è¡Œè„šæœ¬
```python
# run_optimization_experiments.py
#!/usr/bin/env python3

import argparse
import torch
from modules.wandb_logger import WandBLogger
from modules.memory_optimizer import MemoryOptimizer
from experiments.precision_study import PrecisionExperiment

def main():
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument('--run_memory_opt', action='store_true', help='è¿è¡Œæ˜¾å­˜ä¼˜åŒ–')
    parser.add_argument('--run_precision_study', action='store_true', help='è¿è¡Œç²¾åº¦å¯¹æ¯”å®éªŒ')
    parser.add_argument('--run_all', action='store_true', help='è¿è¡Œæ‰€æœ‰ä¼˜åŒ–å®éªŒ')
    args = parser.parse_args()
    
    # åˆå§‹åŒ–WandB
    wandb_logger = WandBLogger()
    
    if args.run_memory_opt or args.run_all:
        print("ğŸš€ å¼€å§‹æ˜¾å­˜ä¼˜åŒ–å®éªŒ...")
        run_memory_optimization(wandb_logger)
    
    if args.run_precision_study or args.run_all:
        print("ğŸš€ å¼€å§‹ç²¾åº¦å¯¹æ¯”å®éªŒ...")
        run_precision_study(wandb_logger)

def run_memory_optimization(wandb_logger):
    """è¿è¡Œæ˜¾å­˜ä¼˜åŒ–å®éªŒ"""
    # å®ç°æ˜¾å­˜ä¼˜åŒ–é€»è¾‘
    pass

def run_precision_study(wandb_logger):
    """è¿è¡Œç²¾åº¦å¯¹æ¯”å®éªŒ"""
    # å®ç°ç²¾åº¦å¯¹æ¯”é€»è¾‘
    pass

if __name__ == '__main__':
    main()
```

## ğŸ“Š å®éªŒè®¾è®¡

### å®éªŒ1: æ˜¾å­˜ä¼˜åŒ–åŸºçº¿æµ‹è¯•
- **ç›®æ ‡**: æ‰¾åˆ°æœ€ä¼˜batch sizeå’Œæ¢¯åº¦ç´¯ç§¯é…ç½®
- **æ–¹æ³•**: é€æ­¥å¢åŠ batch sizeç›´åˆ°æ˜¾å­˜ä½¿ç”¨ç‡è¾¾åˆ°85%
- **ç›‘æ§**: GPUæ˜¾å­˜ä½¿ç”¨ç‡ã€è®­ç»ƒé€Ÿåº¦ã€æ¨¡å‹æ€§èƒ½

### å®éªŒ2: ç²¾åº¦å¯¹æ¯”ç ”ç©¶
- **é…ç½®**: FP32 vs FP16 vs FP8
- **è®­ç»ƒ**: æ¯ç§ç²¾åº¦15ä¸ªepoch
- **è¯„ä¼°**: 
  - è®­ç»ƒé€Ÿåº¦ (samples/sec)
  - æ˜¾å­˜ä½¿ç”¨é‡
  - æ¨¡å‹æ€§èƒ½ (BLEU, METEOR, ROUGE-L)
  - æ•°å€¼ç¨³å®šæ€§

### å®éªŒ3: ç»¼åˆä¼˜åŒ–
- **ç»“åˆ**: æœ€ä¼˜batch size + æœ€ä½³ç²¾åº¦è®¾ç½®
- **é•¿æœŸè®­ç»ƒ**: 100 epochs
- **å¯¹æ¯”**: ä¸åŸå§‹é…ç½®çš„æ€§èƒ½å¯¹æ¯”

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### WandBç›‘æ§æŒ‡æ ‡
```yaml
è®­ç»ƒæŒ‡æ ‡:
  - train_loss, val_loss, test_loss
  - BLEU-1/2/3/4, METEOR, ROUGE-L
  - learning_rate, gradient_norm

ç³»ç»ŸæŒ‡æ ‡:
  - GPUåˆ©ç”¨ç‡ã€æ˜¾å­˜ä½¿ç”¨ç‡ã€æ¸©åº¦
  - CPUä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ç‡
  - è®­ç»ƒé€Ÿåº¦ (samples/sec, batches/sec)

æ¨¡å‹æŒ‡æ ‡:
  - å‚æ•°æ•°é‡ã€æ¨¡å‹å¤§å°
  - å‰å‘ä¼ æ’­æ—¶é—´ã€åå‘ä¼ æ’­æ—¶é—´
```

### æ¢¯åº¦ç´¯ç§¯å®ç°
```python
# åœ¨trainerä¸­å®ç°æ¢¯åº¦ç´¯ç§¯
def _train_epoch_with_accumulation(self, epoch):
    self.model.train()
    accumulated_loss = 0
    
    for batch_idx, batch_data in enumerate(self.train_dataloader):
        # å‰å‘ä¼ æ’­
        loss = self._forward_step(batch_data) / self.gradient_accumulation_steps
        
        # åå‘ä¼ æ’­ï¼ˆç´¯ç§¯æ¢¯åº¦ï¼‰
        if self.mixed_precision == 'fp16':
            self.scaler.scale(loss).backward()
        else:
            loss.backward()
        
        accumulated_loss += loss.item()
        
        # æ¯accumulation_stepsæ­¥æ›´æ–°ä¸€æ¬¡å‚æ•°
        if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
            if self.mixed_precision == 'fp16':
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                self.optimizer.step()
            
            self.optimizer.zero_grad()
```

## ğŸ“ˆ é¢„æœŸæ”¶ç›Š

1. **æ€§èƒ½æå‡**: é€šè¿‡FP16å¯èƒ½è·å¾—1.5-2xè®­ç»ƒé€Ÿåº¦æå‡
2. **æ˜¾å­˜ä¼˜åŒ–**: é€šè¿‡åŠ¨æ€batch sizeæœ€å¤§åŒ–GPUåˆ©ç”¨ç‡
3. **ç›‘æ§å®Œå–„**: å…¨é¢çš„è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å’Œåˆ†æ
4. **å®éªŒå¯é‡ç°**: è¯¦ç»†çš„å®éªŒè®°å½•å’Œé…ç½®ç®¡ç†

## âš ï¸ é£é™©è¯„ä¼°

1. **æ•°å€¼ç¨³å®šæ€§**: FP16å¯èƒ½å¯¼è‡´æ¢¯åº¦ä¸‹æº¢ï¼Œéœ€è¦æ¢¯åº¦ç¼©æ”¾
2. **æ¨¡å‹æ€§èƒ½**: ä½ç²¾åº¦å¯èƒ½å½±å“æœ€ç»ˆæ¨¡å‹æ•ˆæœ
3. **ç¡¬ä»¶å…¼å®¹**: FP8éœ€è¦è¾ƒæ–°çš„GPUæ”¯æŒ
4. **å®éªŒæ—¶é—´**: å®Œæ•´çš„ç²¾åº¦å¯¹æ¯”å®éªŒéœ€è¦è¾ƒé•¿æ—¶é—´

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

1. **æŠ€æœ¯æŒ‡æ ‡**:
   - è®­ç»ƒé€Ÿåº¦æå‡ > 30%
   - æ˜¾å­˜åˆ©ç”¨ç‡ > 80%
   - æ¨¡å‹æ€§èƒ½æŸå¤± < 5%

2. **ç›‘æ§æŒ‡æ ‡**:
   - å®Œæ•´çš„WandBä»ªè¡¨æ¿
   - å®æ—¶ç¡¬ä»¶æ€§èƒ½ç›‘æ§
   - è‡ªåŠ¨åŒ–å®éªŒè®°å½•

è¿™ä¸ªæ–¹æ¡ˆå¦‚ä½•ï¼Ÿéœ€è¦æˆ‘è°ƒæ•´æˆ–è¡¥å……å“ªäº›éƒ¨åˆ†ï¼Ÿ
