#!/usr/bin/env python3
"""
æ·±å…¥è°ƒè¯•BatchNormç»´åº¦é—®é¢˜
"""

import sys
import torch
import torch.nn as nn
import traceback

sys.path.append('R2Gen-main')

def debug_att_embed_creation():
    """è°ƒè¯•att_embedå±‚çš„åˆ›å»ºè¿‡ç¨‹"""
    print("ğŸ” è°ƒè¯•att_embedå±‚åˆ›å»º...")
    
    try:
        from modules.tokenizers import Tokenizer
        from models.r2gen import R2GenModel
        import argparse
        
        # åˆ›å»ºå®Œæ•´çš„å‚æ•°é…ç½®
        args = argparse.Namespace()
        args.ann_path = 'datasets/iu_xray/annotation.json'
        args.threshold = 3
        args.dataset_name = 'iu_xray'
        args.image_dir = 'datasets/iu_xray/images/'
        args.max_seq_length = 60
        args.d_model = 512
        args.d_ff = 512
        args.d_vf = 2048
        args.num_heads = 8
        args.num_layers = 3
        args.dropout = 0.1
        args.logit_layers = 1
        args.bos_idx = 0
        args.eos_idx = 0
        args.pad_idx = 0
        args.use_bn = True
        args.rm_num_slots = 3
        args.rm_num_heads = 8
        args.rm_d_model = 512
        args.visual_extractor = 'resnet101'
        args.visual_extractor_pretrained = True
        args.sample_method = 'beam_search'
        args.beam_size = 3
        args.temperature = 1.0
        args.sample_n = 1
        args.drop_prob_lm = 0.5
        
        print(f"é…ç½®å‚æ•°:")
        print(f"  d_vf (att_feat_size): {args.d_vf}")
        print(f"  d_model (input_encoding_size): {args.d_model}")
        print(f"  use_bn: {args.use_bn}")
        
        # åˆ›å»ºtokenizer
        tokenizer = Tokenizer(args)
        print(f"  vocab_size: {len(tokenizer.idx2token)}")
        
        # åˆ›å»ºæ¨¡å‹å¹¶æ£€æŸ¥att_embedå±‚
        model = R2GenModel(args, tokenizer)
        
        # æ£€æŸ¥att_embedå±‚çš„ç»“æ„
        att_embed = model.encoder_decoder.att_embed
        print(f"\nğŸ“Š att_embedå±‚ç»“æ„:")
        for i, layer in enumerate(att_embed):
            print(f"  [{i}] {layer}")
            if isinstance(layer, nn.BatchNorm1d):
                print(f"      num_features: {layer.num_features}")
                print(f"      running_mean shape: {layer.running_mean.shape}")
                print(f"      running_var shape: {layer.running_var.shape}")
        
        # æµ‹è¯•æ•°æ®æµ
        print(f"\nğŸ§ª æµ‹è¯•æ•°æ®æµ...")
        batch_size = 2
        seq_len = 49
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        att_feats = torch.randn(batch_size, seq_len, args.d_vf)
        print(f"è¾“å…¥att_featså½¢çŠ¶: {att_feats.shape}")
        
        # é€å±‚æµ‹è¯•
        x = att_feats
        for i, layer in enumerate(att_embed):
            print(f"\n  å±‚ [{i}] {type(layer).__name__}:")
            print(f"    è¾“å…¥å½¢çŠ¶: {x.shape}")
            
            if isinstance(layer, nn.BatchNorm1d):
                # BatchNorm1déœ€è¦(N, C)æˆ–(N, C, L)æ ¼å¼
                print(f"    BatchNorm1dæœŸæœ›: (batch_size, num_features) æˆ– (batch_size, num_features, seq_len)")
                print(f"    å½“å‰è¾“å…¥: {x.shape}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦reshape
                if len(x.shape) == 3:
                    # (batch_size, seq_len, features) -> (batch_size, features, seq_len)
                    x_reshaped = x.transpose(1, 2)
                    print(f"    è½¬ç½®åå½¢çŠ¶: {x_reshaped.shape}")
                    try:
                        output = layer(x_reshaped)
                        x = output.transpose(1, 2)  # è½¬å›åŸæ ¼å¼
                        print(f"    è¾“å‡ºå½¢çŠ¶: {x.shape}")
                    except Exception as e:
                        print(f"    âŒ BatchNormå¤±è´¥: {e}")
                        break
                else:
                    try:
                        x = layer(x)
                        print(f"    è¾“å‡ºå½¢çŠ¶: {x.shape}")
                    except Exception as e:
                        print(f"    âŒ BatchNormå¤±è´¥: {e}")
                        break
            else:
                try:
                    x = layer(x)
                    print(f"    è¾“å‡ºå½¢çŠ¶: {x.shape}")
                except Exception as e:
                    print(f"    âŒ å±‚å¤±è´¥: {e}")
                    break
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        traceback.print_exc()

def test_batchnorm_input_format():
    """æµ‹è¯•BatchNorm1dçš„è¾“å…¥æ ¼å¼è¦æ±‚"""
    print("\nğŸ” æµ‹è¯•BatchNorm1dè¾“å…¥æ ¼å¼...")
    
    batch_size = 2
    seq_len = 49
    features = 2048
    
    # åˆ›å»ºBatchNorm1d
    bn = nn.BatchNorm1d(features)
    print(f"BatchNorm1d(num_features={features})")
    
    # æµ‹è¯•ä¸åŒçš„è¾“å…¥æ ¼å¼
    formats = [
        ("(batch, features)", (batch_size, features)),
        ("(batch, features, seq)", (batch_size, features, seq_len)),
        ("(batch, seq, features)", (batch_size, seq_len, features)),
    ]
    
    for name, shape in formats:
        print(f"\n  æµ‹è¯•æ ¼å¼ {name}: {shape}")
        x = torch.randn(shape)
        try:
            output = bn(x)
            print(f"    âœ… æˆåŠŸ: è¾“å‡ºå½¢çŠ¶ {output.shape}")
        except Exception as e:
            print(f"    âŒ å¤±è´¥: {e}")

def check_model_state_dict():
    """æ£€æŸ¥æ¨¡å‹çŠ¶æ€å­—å…¸ä¸­çš„BatchNormå‚æ•°"""
    print("\nğŸ” æ£€æŸ¥æ¨¡å‹çŠ¶æ€å­—å…¸...")
    
    try:
        from modules.tokenizers import Tokenizer
        from models.r2gen import R2GenModel
        import argparse
        
        # åˆ›å»ºå‚æ•°
        args = argparse.Namespace()
        args.ann_path = 'datasets/iu_xray/annotation.json'
        args.threshold = 3
        args.dataset_name = 'iu_xray'
        args.image_dir = 'datasets/iu_xray/images/'
        args.max_seq_length = 60
        args.d_model = 512
        args.d_ff = 512
        args.d_vf = 2048
        args.num_heads = 8
        args.num_layers = 3
        args.dropout = 0.1
        args.logit_layers = 1
        args.bos_idx = 0
        args.eos_idx = 0
        args.pad_idx = 0
        args.use_bn = True
        args.rm_num_slots = 3
        args.rm_num_heads = 8
        args.rm_d_model = 512
        args.visual_extractor = 'resnet101'
        args.visual_extractor_pretrained = True
        args.sample_method = 'beam_search'
        args.beam_size = 3
        args.temperature = 1.0
        args.sample_n = 1
        args.drop_prob_lm = 0.5
        
        tokenizer = Tokenizer(args)
        model = R2GenModel(args, tokenizer)
        
        # æ£€æŸ¥att_embedç›¸å…³çš„å‚æ•°
        state_dict = model.state_dict()
        
        print("ğŸ“Š att_embedç›¸å…³å‚æ•°:")
        for key, value in state_dict.items():
            if 'att_embed' in key:
                print(f"  {key}: {value.shape}")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ·±å…¥è°ƒè¯•BatchNormç»´åº¦é—®é¢˜...")
    
    test_batchnorm_input_format()
    debug_att_embed_creation()
    check_model_state_dict()

if __name__ == "__main__":
    main()
