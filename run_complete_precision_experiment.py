#!/usr/bin/env python3
"""
å®Œæ•´çš„R2Genç²¾åº¦å¯¹æ¯”å®éªŒ
ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡"Generating Radiology Reports via Memory-driven Transformer"é…ç½®
"""

import os
import sys
import time
import json
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('R2Gen-main')

from modules.tokenizers import Tokenizer
from modules.dataloaders import R2DataLoader
from modules.metrics import compute_scores
from modules.optimizers import build_optimizer, build_lr_scheduler
from modules.loss import compute_loss
from models.r2gen import R2GenModel
from modules.wandb_logger import WandBLogger
from modules.memory_monitor import MemoryMonitor
from modules.enhanced_trainer import EnhancedTrainer
# from modules.batch_size_optimizer import BatchSizeOptimizer  # æš‚æ—¶ä¸ä½¿ç”¨

class PrecisionExperimentConfig:
    """ç²¾åº¦å®éªŒé…ç½®ç±» - ä¸¥æ ¼æŒ‰ç…§è®ºæ–‡é…ç½®"""
    
    def __init__(self, precision, epochs=15):
        # åŸºç¡€é…ç½®
        self.precision = precision
        self.epochs = epochs
        
        # æ•°æ®é›†ç›¸å…³
        self.image_dir = 'datasets/iu_xray/images/'
        self.ann_path = 'datasets/iu_xray/annotation.json'
        self.dataset_name = 'iu_xray'
        self.max_seq_length = 60
        self.threshold = 3
        self.num_workers = 2
        self.batch_size = 12  # é»˜è®¤batch sizeï¼Œä¼šè¢«åŠ¨æ€è°ƒæ•´
        
        # è®­ç»ƒç›¸å…³ - æŒ‰è®ºæ–‡é…ç½®
        self.seed = 9223
        self.n_gpu = 1
        self.save_period = 1  # æ¯ä¸ªepochä¿å­˜
        self.monitor_mode = 'max'
        self.monitor_metric = 'BLEU_4'
        self.early_stop = 50  # å…è®¸æ›´å¤šepoch
        self.resume = None
        self.validate_every = 1  # æ¯ä¸ªepochéªŒè¯
        
        # ä¼˜åŒ–å™¨ç›¸å…³ - ä¸¥æ ¼æŒ‰è®ºæ–‡é…ç½®
        self.optim = 'Adam'
        self.lr_ve = 5e-5      # visual extractorå­¦ä¹ ç‡
        self.lr_ed = 1e-4      # encoder-decoderå­¦ä¹ ç‡
        self.weight_decay = 0
        self.amsgrad = True
        
        # å­¦ä¹ ç‡è°ƒåº¦ - æŒ‰è®ºæ–‡è¦æ±‚æ¯epochè¡°å‡0.8
        self.lr_scheduler = 'StepLR'
        self.step_size = 1     # æ¯ä¸ªepochè¡°å‡
        self.gamma = 0.8       # è¡°å‡å› å­0.8
        
        # æ¨¡å‹ç›¸å…³ - ä¸¥æ ¼æŒ‰è®ºæ–‡Table 3é…ç½®
        self.d_model = 512
        self.d_ff = 512
        self.d_vf = 2048
        self.num_heads = 8
        self.num_layers = 3
        self.dropout = 0.1
        self.logit_layers = 1
        self.bos_idx = 0
        self.eos_idx = 0
        self.pad_idx = 0
        self.use_bn = True
        
        # è®°å¿†æ¨¡å— - æŒ‰è®ºæ–‡é…ç½®
        self.rm_num_slots = 3
        self.rm_num_heads = 8
        self.rm_d_model = 512
        
        # è§†è§‰ç‰¹å¾æå–
        self.visual_extractor = 'resnet101'
        self.visual_extractor_pretrained = True
        
        # é‡‡æ ·ç›¸å…³ - æŒ‰è®ºæ–‡é…ç½®
        self.sample_method = 'beam_search'
        self.beam_size = 3
        self.temperature = 1.0
        self.sample_n = 1
        
        # æ··åˆç²¾åº¦é…ç½®
        if precision == 'fp16':
            self.mixed_precision = True
            self.precision_mode = 'fp16'
        elif precision == 'fp8':
            self.mixed_precision = True
            self.precision_mode = 'fp8'
        else:
            self.mixed_precision = False
            self.precision_mode = 'fp32'
        
        # ä¿å­˜è·¯å¾„
        self.save_dir = f'results/precision_comparison/{precision}'
        self.record_dir = f'results/precision_comparison/{precision}'
        self.experiment_name = f'R2Gen_{precision}_precision'
        
        # å…¶ä»–å¿…éœ€å‚æ•°
        self.drop_prob_lm = 0.5

def run_precision_experiment(precision, epochs=15):
    """è¿è¡Œå•ä¸ªç²¾åº¦å®éªŒ"""
    
    print(f"\n{'='*60}")
    print(f"å¼€å§‹ {precision.upper()} å®éªŒ")
    print(f"æè¿°: {get_precision_description(precision)}")
    print(f"{'='*60}")
    
    # åˆ›å»ºé…ç½®
    args = PrecisionExperimentConfig(precision, epochs)
    
    # æ ¹æ®ç²¾åº¦è®¾ç½®batch size
    if precision == 'fp32':
        batch_size = 12  # åŸºå‡†batch size
    elif precision == 'fp16':
        batch_size = 16  # FP16å¯ä»¥ä½¿ç”¨æ›´å¤§batch size
    else:  # fp8
        batch_size = 20  # FP8å¯ä»¥ä½¿ç”¨æœ€å¤§batch size

    # æ›´æ–°argsä¸­çš„batch_size
    args.batch_size = batch_size
    
    print(f"\nğŸš€ å¼€å§‹ {precision.upper()} ç²¾åº¦è®­ç»ƒ...")
    print(f"   Batch Size: {batch_size}")
    print(f"   Epochs: {epochs}")
    print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"   ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    tokenizer = Tokenizer(args)
    train_dataloader = R2DataLoader(args, tokenizer, split='train', shuffle=True)
    val_dataloader = R2DataLoader(args, tokenizer, split='val', shuffle=False)
    test_dataloader = R2DataLoader(args, tokenizer, split='test', shuffle=False)
    
    print(f"   è®­ç»ƒæ ·æœ¬: {len(train_dataloader.dataset)}")
    print(f"   éªŒè¯æ ·æœ¬: {len(val_dataloader.dataset)}")
    print(f"   æµ‹è¯•æ ·æœ¬: {len(test_dataloader.dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"   ğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
    model = R2GenModel(args, tokenizer).cuda()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = build_optimizer(args, model)
    lr_scheduler = build_lr_scheduler(args, optimizer)
    
    # åˆå§‹åŒ–WandB
    print(f"   ğŸ“ˆ åˆå§‹åŒ–WandBç›‘æ§...")
    # è®¾ç½®API key
    os.environ['WANDB_API_KEY'] = '68c9ce2a167992d06678c4fdc0d1075b5dfff922'
    wandb_logger = WandBLogger(project_name="R2Gen-Complete-Precision-Comparison")
    
    wandb_config = {
        'precision': precision,
        'mixed_precision': args.mixed_precision,
        'batch_size': batch_size,
        'epochs': epochs,
        'learning_rate_ve': args.lr_ve,
        'learning_rate_ed': args.lr_ed,
        'lr_scheduler': args.lr_scheduler,
        'lr_decay_factor': args.gamma,
        'lr_decay_step': args.step_size,
        'model': 'R2Gen',
        'dataset': args.dataset_name,
        'experiment_type': 'complete_precision_comparison',
        'optimizer': args.optim,
        'rm_num_slots': args.rm_num_slots,
        'rm_d_model': args.rm_d_model,
        'beam_size': args.beam_size,
        'd_model': args.d_model,
        'num_layers': args.num_layers,
        'num_heads': args.num_heads
    }
    
    run_name = f"R2Gen_{precision}_complete_bs{batch_size}_ep{epochs}"
    wandb_logger.init_run(wandb_config, run_name=run_name)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    print(f"   ğŸ¯ åˆ›å»ºè®­ç»ƒå™¨...")
    trainer = EnhancedTrainer(
        model=model,
        criterion=compute_loss,
        metric_ftns=compute_scores,
        optimizer=optimizer,
        args=args,
        lr_scheduler=lr_scheduler,
        train_dataloader=train_dataloader,
        val_dataloader=val_dataloader,
        test_dataloader=test_dataloader,
        wandb_logger=wandb_logger,
        enable_wandb=True
    )
    
    # å¼€å§‹è®­ç»ƒ
    print(f"   ğŸƒ å¼€å§‹è®­ç»ƒ...")
    start_time = time.time()
    
    try:
        trainer.train()
        training_time = (time.time() - start_time) / 3600  # è½¬æ¢ä¸ºå°æ—¶
        
        print(f"   âœ… {precision.upper()} è®­ç»ƒæˆåŠŸå®Œæˆ!")
        wandb_logger.finish()
        
        return {
            'precision': precision,
            'status': 'success',
            'training_time_hours': training_time,
            'batch_size': batch_size,
            'epochs': epochs,
            'model_path': f'{args.save_dir}/model_best.pth'
        }
        
    except Exception as e:
        print(f"   âŒ {precision.upper()} è®­ç»ƒå¤±è´¥: {str(e)}")
        wandb_logger.finish()
        
        return {
            'precision': precision,
            'status': 'failed',
            'error': str(e),
            'batch_size': batch_size,
            'epochs': epochs
        }

def get_precision_description(precision):
    """è·å–ç²¾åº¦æè¿°"""
    descriptions = {
        'fp32': 'Full Precision (FP32)',
        'fp16': 'Half Precision (FP16) with Mixed Precision Training',
        'fp8': 'Quarter Precision (FP8) with Mixed Precision Training'
    }
    return descriptions.get(precision, 'Unknown Precision')

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å®Œæ•´R2Genç²¾åº¦å¯¹æ¯”å®éªŒ')
    parser.add_argument('--epochs', type=int, default=15, help='è®­ç»ƒepochæ•°')
    parser.add_argument('--precisions', nargs='+', default=['fp8', 'fp16', 'fp32'], 
                       help='è¦æµ‹è¯•çš„ç²¾åº¦åˆ—è¡¨')
    
    args = parser.parse_args()
    
    print("ğŸš€ R2Genå®Œæ•´ç²¾åº¦å¯¹æ¯”å®éªŒ")
    print(f"   ç²¾åº¦èŒƒå›´: {', '.join(args.precisions)}")
    print(f"   è®­ç»ƒepochs: {args.epochs}")
    print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   å°†è¿è¡Œç²¾åº¦: {args.precisions}")
    
    # éªŒè¯å‰ç½®æ¡ä»¶
    print(f"\nğŸ“‹ éªŒè¯å‰ç½®æ¡ä»¶...")
    
    # éªŒè¯tokenizerè§£ç 
    sys.path.append('R2Gen-main')
    from modules.tokenizers import Tokenizer
    import argparse as arg_ns
    
    test_args = arg_ns.Namespace()
    test_args.ann_path = 'datasets/iu_xray/annotation.json'
    test_args.threshold = 3
    test_args.dataset_name = 'iu_xray'
    
    tokenizer = Tokenizer(test_args)
    test_text = 'the lungs are clear'
    encoded = tokenizer(test_text)
    decoded = tokenizer.decode(encoded)
    
    if len(decoded) == 0:
        print("âŒ Tokenizerè§£ç å¤±è´¥ï¼Œå®éªŒç»ˆæ­¢")
        return
    else:
        print("âœ… Tokenizerè§£ç æ­£å¸¸")
    
    # æ‰§è¡Œå®éªŒ
    results = []
    
    for precision in args.precisions:
        result = run_precision_experiment(precision, args.epochs)
        results.append(result)
        
        # æ£€æŸ¥BLEUåˆ†æ•°åˆç†æ€§
        if result['status'] == 'success':
            print(f"âœ… {precision.upper()} å®éªŒæˆåŠŸ")
        else:
            print(f"âŒ {precision.upper()} å®éªŒå¤±è´¥: {result.get('error', 'Unknown error')}")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = f'complete_precision_results_{timestamp}.json'
    
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print(f"ğŸ‰ å®Œæ•´ç²¾åº¦å¯¹æ¯”å®éªŒå®Œæˆ!")
    print(f"{'='*60}")
    
    successful_experiments = [r for r in results if r['status'] == 'success']
    failed_experiments = [r for r in results if r['status'] == 'failed']
    
    print(f"âœ… æˆåŠŸå®éªŒ: {len(successful_experiments)}/{len(results)}")
    
    if successful_experiments:
        print(f"\nâ±ï¸ è®­ç»ƒæ—¶é—´å¯¹æ¯”:")
        for result in successful_experiments:
            print(f"   {result['precision'].upper()}: {result['training_time_hours']:.2f} å°æ—¶")
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        fp32_time = next((r['training_time_hours'] for r in successful_experiments if r['precision'] == 'fp32'), None)
        if fp32_time:
            print(f"\nğŸš€ ç›¸å¯¹FP32çš„åŠ é€Ÿæ¯”:")
            for result in successful_experiments:
                if result['precision'] != 'fp32':
                    speedup = (fp32_time - result['training_time_hours']) / fp32_time * 100
                    print(f"   {result['precision'].upper()}: {speedup:.1f}% æ›´å¿«")
    
    if failed_experiments:
        print(f"\nâŒ å¤±è´¥å®éªŒ:")
        for result in failed_experiments:
            print(f"   {result['precision'].upper()}: {result.get('error', 'Unknown error')}")
    
    print(f"\nğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®:")
    for result in successful_experiments:
        print(f"   {result['precision'].upper()}: {result['model_path']}")
    
    print(f"\nğŸ“Š ç»“æœæ–‡ä»¶: {results_file}")
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: ç”Ÿæˆå®Œæ•´HTMLæŠ¥å‘Š")
    print(f"   ä½¿ç”¨å‘½ä»¤: python generate_complete_precision_report.py")

if __name__ == "__main__":
    main()
