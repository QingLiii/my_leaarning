"""
WandBç›‘æ§ç³»ç»Ÿ - å…¨æ–¹ä½è®­ç»ƒå’Œç³»ç»Ÿæ€§èƒ½ç›‘æ§
æ”¯æŒè®­ç»ƒæŒ‡æ ‡ã€ç³»ç»Ÿæ€§èƒ½ã€GPUç›‘æ§ç­‰åŠŸèƒ½
"""

import wandb
import torch
import psutil
import time
import os
import subprocess
from typing import Dict, Any, Optional
import numpy as np
from collections import defaultdict

try:
    import GPUtil
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False
    print("âš ï¸ GPUtilæœªå®‰è£…ï¼ŒGPUç›‘æ§åŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import nvidia_ml_py3 as nvml
    nvml.nvmlInit()
    NVML_AVAILABLE = True
except ImportError:
    NVML_AVAILABLE = False
    print("âš ï¸ nvidia-ml-py3æœªå®‰è£…ï¼Œè¯¦ç»†GPUç›‘æ§åŠŸèƒ½å°†è¢«ç¦ç”¨")


class WandBLogger:
    """
    WandBç›‘æ§ç³»ç»Ÿä¸»ç±»
    æä¾›å…¨æ–¹ä½çš„è®­ç»ƒè¿‡ç¨‹å’Œç³»ç»Ÿæ€§èƒ½ç›‘æ§
    """
    
    def __init__(self, 
                 project_name: str = "R2Gen-Optimization",
                 api_key: str = "68c9ce2a167992d06678c4fdc0d1075b5dfff922",
                 log_system_interval: int = 10):
        """
        åˆå§‹åŒ–WandBç›‘æ§ç³»ç»Ÿ
        
        Args:
            project_name: WandBé¡¹ç›®åç§°
            api_key: WandB APIå¯†é’¥
            log_system_interval: ç³»ç»Ÿç›‘æ§è®°å½•é—´éš”ï¼ˆæ‰¹æ¬¡æ•°ï¼‰
        """
        self.project_name = project_name
        self.api_key = api_key
        self.log_system_interval = log_system_interval
        self.batch_count = 0
        self.epoch_start_time = None
        self.batch_times = []
        
        # ç™»å½•WandB
        try:
            wandb.login(key=api_key)
            print("âœ… WandBç™»å½•æˆåŠŸ")
        except Exception as e:
            print(f"âŒ WandBç™»å½•å¤±è´¥: {e}")
            raise
    
    def init_run(self, 
                 config: Dict[str, Any], 
                 run_name: Optional[str] = None,
                 tags: Optional[list] = None):
        """
        åˆå§‹åŒ–WandBè¿è¡Œ
        
        Args:
            config: è®­ç»ƒé…ç½®å‚æ•°
            run_name: è¿è¡Œåç§°
            tags: æ ‡ç­¾åˆ—è¡¨
        """
        if tags is None:
            tags = ["optimization", "monitoring"]
        
        # æ·»åŠ ç³»ç»Ÿä¿¡æ¯åˆ°é…ç½®
        config.update(self._get_system_info())
        
        wandb.init(
            project=self.project_name,
            config=config,
            name=run_name,
            tags=tags,
            reinit=True
        )
        
        print(f"ğŸš€ WandBè¿è¡Œåˆå§‹åŒ–å®Œæˆ: {wandb.run.name}")
        
        # è®°å½•åˆå§‹ç³»ç»ŸçŠ¶æ€
        self.log_system_metrics(force=True)
    
    def _get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸåŸºç¡€ä¿¡æ¯"""
        info = {
            'system/python_version': f"{psutil.sys.version_info.major}.{psutil.sys.version_info.minor}",
            'system/cpu_count': psutil.cpu_count(),
            'system/memory_total_gb': psutil.virtual_memory().total / (1024**3),
            'system/torch_version': torch.__version__,
            'system/cuda_available': torch.cuda.is_available(),
        }

        if torch.cuda.is_available():
            # è·å–è¯¦ç»†GPUä¿¡æ¯
            gpu_props = torch.cuda.get_device_properties(0)
            capability = torch.cuda.get_device_capability(0)

            info.update({
                'system/cuda_version': torch.version.cuda,
                'system/gpu_count': torch.cuda.device_count(),
                'system/gpu_name': torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "Unknown",
                'system/gpu_memory_total_gb': gpu_props.total_memory / (1024**3),
                'system/gpu_compute_capability': f"{capability[0]}.{capability[1]}",
                'system/gpu_multiprocessor_count': gpu_props.multi_processor_count,
            })
        
        return info
    
    def log_system_metrics(self, force: bool = False):
        """
        è®°å½•ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
        
        Args:
            force: å¼ºåˆ¶è®°å½•ï¼ˆå¿½ç•¥é—´éš”é™åˆ¶ï¼‰
        """
        if not force and self.batch_count % self.log_system_interval != 0:
            return
        
        metrics = {}
        
        # CPUå’Œå†…å­˜ç›‘æ§
        cpu_percent = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        
        metrics.update({
            'system/cpu_percent': cpu_percent,
            'system/memory_percent': memory.percent,
            'system/memory_used_gb': memory.used / (1024**3),
            'system/memory_available_gb': memory.available / (1024**3),
        })
        
        # GPUç›‘æ§
        if GPU_AVAILABLE:
            gpu_metrics = self._get_gpu_metrics()
            metrics.update(gpu_metrics)
        
        # è¯¦ç»†GPUç›‘æ§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if NVML_AVAILABLE:
            detailed_gpu_metrics = self._get_detailed_gpu_metrics()
            metrics.update(detailed_gpu_metrics)
        
        # è¿›ç¨‹ç›‘æ§
        process_metrics = self._get_process_metrics()
        metrics.update(process_metrics)
        
        wandb.log(metrics)
    
    def _get_gpu_metrics(self) -> Dict[str, float]:
        """è·å–GPUåŸºç¡€ç›‘æ§æŒ‡æ ‡"""
        metrics = {}
        
        try:
            gpus = GPUtil.getGPUs()
            for i, gpu in enumerate(gpus):
                prefix = f'gpu_{i}'
                metrics.update({
                    f'{prefix}/utilization_percent': gpu.load * 100,
                    f'{prefix}/memory_used_mb': gpu.memoryUsed,
                    f'{prefix}/memory_total_mb': gpu.memoryTotal,
                    f'{prefix}/memory_percent': (gpu.memoryUsed / gpu.memoryTotal) * 100,
                    f'{prefix}/memory_free_mb': gpu.memoryFree,
                    f'{prefix}/temperature_c': gpu.temperature,
                })
        except Exception as e:
            print(f"âš ï¸ GPUç›‘æ§é”™è¯¯: {e}")
        
        return metrics
    
    def _get_detailed_gpu_metrics(self) -> Dict[str, float]:
        """è·å–è¯¦ç»†GPUç›‘æ§æŒ‡æ ‡ï¼ˆéœ€è¦nvidia-ml-py3ï¼‰"""
        metrics = {}
        
        try:
            device_count = nvml.nvmlDeviceGetCount()
            for i in range(device_count):
                handle = nvml.nvmlDeviceGetHandleByIndex(i)
                prefix = f'gpu_{i}'
                
                # åŠŸè€—ç›‘æ§
                try:
                    power_draw = nvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # è½¬æ¢ä¸ºç“¦ç‰¹
                    power_limit = nvml.nvmlDeviceGetPowerManagementLimitConstraints(handle)[1] / 1000.0
                    metrics[f'{prefix}/power_draw_w'] = power_draw
                    metrics[f'{prefix}/power_limit_w'] = power_limit
                    metrics[f'{prefix}/power_percent'] = (power_draw / power_limit) * 100
                except:
                    pass
                
                # æ—¶é’Ÿé¢‘ç‡
                try:
                    graphics_clock = nvml.nvmlDeviceGetClockInfo(handle, nvml.NVML_CLOCK_GRAPHICS)
                    memory_clock = nvml.nvmlDeviceGetClockInfo(handle, nvml.NVML_CLOCK_MEM)
                    metrics[f'{prefix}/graphics_clock_mhz'] = graphics_clock
                    metrics[f'{prefix}/memory_clock_mhz'] = memory_clock
                except:
                    pass
                
                # é£æ‰‡é€Ÿåº¦
                try:
                    fan_speed = nvml.nvmlDeviceGetFanSpeed(handle)
                    metrics[f'{prefix}/fan_speed_percent'] = fan_speed
                except:
                    pass
        
        except Exception as e:
            print(f"âš ï¸ è¯¦ç»†GPUç›‘æ§é”™è¯¯: {e}")
        
        return metrics
    
    def _get_process_metrics(self) -> Dict[str, float]:
        """è·å–å½“å‰è¿›ç¨‹ç›‘æ§æŒ‡æ ‡"""
        metrics = {}
        
        try:
            process = psutil.Process()
            
            # è¿›ç¨‹CPUå’Œå†…å­˜
            metrics.update({
                'process/cpu_percent': process.cpu_percent(),
                'process/memory_percent': process.memory_percent(),
                'process/memory_rss_gb': process.memory_info().rss / (1024**3),
                'process/memory_vms_gb': process.memory_info().vms / (1024**3),
                'process/num_threads': process.num_threads(),
            })
            
            # æ–‡ä»¶æè¿°ç¬¦
            try:
                metrics['process/num_fds'] = process.num_fds()
            except:
                pass  # Windowsä¸æ”¯æŒ
                
        except Exception as e:
            print(f"âš ï¸ è¿›ç¨‹ç›‘æ§é”™è¯¯: {e}")
        
        return metrics
    
    def log_training_metrics(self, 
                           epoch: int,
                           batch_idx: int,
                           loss: float,
                           learning_rate: float,
                           **kwargs):
        """
        è®°å½•è®­ç»ƒæŒ‡æ ‡
        
        Args:
            epoch: å½“å‰epoch
            batch_idx: å½“å‰batchç´¢å¼•
            loss: æŸå¤±å€¼
            learning_rate: å­¦ä¹ ç‡
            **kwargs: å…¶ä»–è®­ç»ƒæŒ‡æ ‡
        """
        self.batch_count += 1
        
        # è®¡ç®—è®­ç»ƒé€Ÿåº¦
        current_time = time.time()
        if hasattr(self, '_last_batch_time'):
            batch_time = current_time - self._last_batch_time
            self.batch_times.append(batch_time)
            
            # ä¿æŒæœ€è¿‘100ä¸ªbatchçš„æ—¶é—´è®°å½•
            if len(self.batch_times) > 100:
                self.batch_times.pop(0)
            
            avg_batch_time = np.mean(self.batch_times)
            batches_per_sec = 1.0 / avg_batch_time if avg_batch_time > 0 else 0
        else:
            batches_per_sec = 0
        
        self._last_batch_time = current_time
        
        # åŸºç¡€è®­ç»ƒæŒ‡æ ‡
        metrics = {
            'train/epoch': epoch,
            'train/batch': batch_idx,
            'train/loss': loss,
            'train/learning_rate': learning_rate,
            'train/batches_per_sec': batches_per_sec,
            'train/global_step': self.batch_count,
        }
        
        # æ·»åŠ å…¶ä»–æŒ‡æ ‡
        for key, value in kwargs.items():
            if isinstance(value, (int, float)):
                metrics[f'train/{key}'] = value
        
        wandb.log(metrics)
        
        # å®šæœŸè®°å½•ç³»ç»ŸæŒ‡æ ‡
        self.log_system_metrics()
    
    def log_validation_metrics(self, epoch: int, metrics_dict: Dict[str, float]):
        """è®°å½•éªŒè¯æŒ‡æ ‡"""
        val_metrics = {}
        for key, value in metrics_dict.items():
            val_metrics[f'val/{key}'] = value
        
        val_metrics['val/epoch'] = epoch
        wandb.log(val_metrics)
    
    def log_test_metrics(self, epoch: int, metrics_dict: Dict[str, float]):
        """è®°å½•æµ‹è¯•æŒ‡æ ‡"""
        test_metrics = {}
        for key, value in metrics_dict.items():
            test_metrics[f'test/{key}'] = value
        
        test_metrics['test/epoch'] = epoch
        wandb.log(test_metrics)
    
    def log_model_info(self, model):
        """è®°å½•æ¨¡å‹ä¿¡æ¯"""
        try:
            # è®¡ç®—å‚æ•°æ•°é‡
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            model_info = {
                'model/total_parameters': total_params,
                'model/trainable_parameters': trainable_params,
                'model/non_trainable_parameters': total_params - trainable_params,
                'model/size_mb': total_params * 4 / (1024**2),  # å‡è®¾float32
            }
            
            wandb.log(model_info)
            
            # è®°å½•æ¨¡å‹ç»“æ„
            wandb.watch(model, log="all", log_freq=1000)
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹ä¿¡æ¯è®°å½•é”™è¯¯: {e}")
    
    def start_epoch(self, epoch: int):
        """å¼€å§‹æ–°çš„epoch"""
        self.epoch_start_time = time.time()
        wandb.log({'epoch/start': epoch})
    
    def end_epoch(self, epoch: int):
        """ç»“æŸå½“å‰epoch"""
        if self.epoch_start_time:
            epoch_time = time.time() - self.epoch_start_time
            wandb.log({
                'epoch/duration_seconds': epoch_time,
                'epoch/duration_minutes': epoch_time / 60,
                'epoch/end': epoch
            })
    
    def log_memory_usage(self, stage: str = ""):
        """è®°å½•è¯¦ç»†å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if torch.cuda.is_available():
            for i in range(torch.cuda.device_count()):
                allocated = torch.cuda.memory_allocated(i) / (1024**3)
                reserved = torch.cuda.memory_reserved(i) / (1024**3)
                max_allocated = torch.cuda.max_memory_allocated(i) / (1024**3)
                
                prefix = f'memory/gpu_{i}'
                if stage:
                    prefix += f'/{stage}'
                
                wandb.log({
                    f'{prefix}/allocated_gb': allocated,
                    f'{prefix}/reserved_gb': reserved,
                    f'{prefix}/max_allocated_gb': max_allocated,
                })
    
    def finish(self):
        """ç»“æŸWandBè¿è¡Œ"""
        try:
            wandb.finish()
            print("âœ… WandBè¿è¡Œå·²ç»“æŸ")
        except Exception as e:
            print(f"âš ï¸ WandBç»“æŸæ—¶å‡ºé”™: {e}")


def install_dependencies():
    """å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…"""
    try:
        import GPUtil
        import nvidia_ml_py3
        print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    except ImportError as e:
        print(f"âš ï¸ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print("pip install GPUtil nvidia-ml-py3 wandb")


if __name__ == "__main__":
    # æµ‹è¯•WandBç›‘æ§ç³»ç»Ÿ
    install_dependencies()
    
    logger = WandBLogger()
    
    # æµ‹è¯•é…ç½®
    test_config = {
        'batch_size': 4,
        'learning_rate': 0.001,
        'epochs': 2,
        'model': 'R2Gen',
        'dataset': 'iu_xray'
    }
    
    logger.init_run(test_config, run_name="wandb_test")
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for epoch in range(2):
        logger.start_epoch(epoch)
        
        for batch in range(10):
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
            loss = 3.0 - epoch * 0.5 - batch * 0.01
            lr = 0.001 * (0.9 ** epoch)
            
            logger.log_training_metrics(
                epoch=epoch,
                batch_idx=batch,
                loss=loss,
                learning_rate=lr,
                gradient_norm=0.5
            )
            
            time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        
        # æ¨¡æ‹ŸéªŒè¯
        val_metrics = {
            'loss': 2.5 - epoch * 0.3,
            'BLEU_4': 0.1 + epoch * 0.05,
            'METEOR': 0.15 + epoch * 0.03
        }
        logger.log_validation_metrics(epoch, val_metrics)
        
        logger.end_epoch(epoch)
    
    logger.finish()
    print("ğŸ‰ WandBæµ‹è¯•å®Œæˆï¼")
