"""
æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨
æ™ºèƒ½ç®¡ç†æ¢¯åº¦ç´¯ç§¯ï¼Œä¿æŒç­‰æ•ˆå¤§batchè®­ç»ƒæ•ˆæœ
"""

import torch
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
import warnings


class GradientAccumulationManager:
    """
    æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    - æ ¹æ®æœ€ä¼˜batch sizeè®¡ç®—ç´¯ç§¯æ­¥æ•°
    - ä¿æŒç­‰æ•ˆå¤§batchè®­ç»ƒæ•ˆæœ
    - åŠ¨æ€è°ƒæ•´ç´¯ç§¯ç­–ç•¥
    - æä¾›æ¢¯åº¦åŒæ­¥æ§åˆ¶
    """
    
    def __init__(self, 
                 target_effective_batch_size: int = 16,
                 min_accumulation_steps: int = 1,
                 max_accumulation_steps: int = 32):
        """
        åˆå§‹åŒ–æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨
        
        Args:
            target_effective_batch_size: ç›®æ ‡ç­‰æ•ˆbatch size
            min_accumulation_steps: æœ€å°ç´¯ç§¯æ­¥æ•°
            max_accumulation_steps: æœ€å¤§ç´¯ç§¯æ­¥æ•°
        """
        self.target_effective_batch_size = target_effective_batch_size
        self.min_accumulation_steps = min_accumulation_steps
        self.max_accumulation_steps = max_accumulation_steps
        
        # å½“å‰é…ç½®
        self.current_batch_size = None
        self.accumulation_steps = 1
        self.effective_batch_size = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.step_count = 0
        self.accumulation_count = 0
        self.gradient_updates = 0
        
        print(f"âœ… æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç›®æ ‡ç­‰æ•ˆbatch size: {target_effective_batch_size}")
        print(f"   ç´¯ç§¯æ­¥æ•°èŒƒå›´: {min_accumulation_steps} - {max_accumulation_steps}")
    
    def calculate_accumulation_steps(self, optimal_batch_size: int) -> int:
        """
        è®¡ç®—æœ€ä¼˜æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
        
        Args:
            optimal_batch_size: æœ€ä¼˜çš„å®é™…batch size
            
        Returns:
            è®¡ç®—å¾—åˆ°çš„ç´¯ç§¯æ­¥æ•°
        """
        # è®¡ç®—ç†æƒ³çš„ç´¯ç§¯æ­¥æ•°
        ideal_steps = self.target_effective_batch_size / optimal_batch_size
        
        # å–æ•´å¹¶é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        accumulation_steps = max(
            self.min_accumulation_steps,
            min(self.max_accumulation_steps, round(ideal_steps))
        )
        
        # æ›´æ–°é…ç½®
        self.current_batch_size = optimal_batch_size
        self.accumulation_steps = accumulation_steps
        self.effective_batch_size = optimal_batch_size * accumulation_steps
        
        # é‡ç½®ç»Ÿè®¡
        self.step_count = 0
        self.accumulation_count = 0
        self.gradient_updates = 0
        
        print(f"\nğŸ“Š æ¢¯åº¦ç´¯ç§¯é…ç½®è®¡ç®—å®Œæˆ:")
        print(f"   å®é™…batch size: {optimal_batch_size}")
        print(f"   ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
        print(f"   ç­‰æ•ˆbatch size: {self.effective_batch_size}")
        print(f"   ç›®æ ‡batch size: {self.target_effective_batch_size}")
        
        # è®¡ç®—æ•ˆæœè¯„ä¼°
        efficiency = (self.effective_batch_size / self.target_effective_batch_size) * 100
        print(f"   ç›®æ ‡è¾¾æˆç‡: {efficiency:.1f}%")
        
        if efficiency < 90:
            print(f"   âš ï¸ ç­‰æ•ˆbatch sizeä½äºç›®æ ‡ï¼Œå¯èƒ½å½±å“è®­ç»ƒæ•ˆæœ")
        elif efficiency > 110:
            print(f"   âš ï¸ ç­‰æ•ˆbatch sizeé«˜äºç›®æ ‡ï¼Œå¯èƒ½å½±å“æ”¶æ•›é€Ÿåº¦")
        else:
            print(f"   âœ… ç­‰æ•ˆbatch sizeæ¥è¿‘ç›®æ ‡ï¼Œé…ç½®åˆç†")
        
        return accumulation_steps
    
    def should_update_gradients(self, step: int) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°æ¢¯åº¦
        
        Args:
            step: å½“å‰æ­¥æ•°ï¼ˆä»0å¼€å§‹ï¼‰
            
        Returns:
            æ˜¯å¦åº”è¯¥æ›´æ–°æ¢¯åº¦
        """
        self.step_count += 1
        self.accumulation_count = (step + 1) % self.accumulation_steps
        
        should_update = (step + 1) % self.accumulation_steps == 0
        
        if should_update:
            self.gradient_updates += 1
        
        return should_update
    
    def get_loss_scale(self) -> float:
        """
        è·å–æŸå¤±ç¼©æ”¾å› å­
        
        Returns:
            æŸå¤±ç¼©æ”¾å› å­ï¼ˆç”¨äºæ¢¯åº¦ç´¯ç§¯ï¼‰
        """
        return 1.0 / self.accumulation_steps
    
    def get_current_config(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰é…ç½®ä¿¡æ¯
        
        Returns:
            å½“å‰é…ç½®å­—å…¸
        """
        return {
            'current_batch_size': self.current_batch_size,
            'accumulation_steps': self.accumulation_steps,
            'effective_batch_size': self.effective_batch_size,
            'target_effective_batch_size': self.target_effective_batch_size,
            'loss_scale': self.get_loss_scale(),
            'efficiency_percent': (self.effective_batch_size / self.target_effective_batch_size) * 100 if self.effective_batch_size else 0
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            'total_steps': self.step_count,
            'gradient_updates': self.gradient_updates,
            'current_accumulation_count': self.accumulation_count,
            'steps_per_update': self.accumulation_steps,
            'avg_steps_per_update': self.step_count / self.gradient_updates if self.gradient_updates > 0 else 0,
            'update_efficiency': (self.gradient_updates * self.accumulation_steps) / self.step_count if self.step_count > 0 else 0
        }
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.step_count = 0
        self.accumulation_count = 0
        self.gradient_updates = 0
        print("ğŸ“Š æ¢¯åº¦ç´¯ç§¯ç»Ÿè®¡å·²é‡ç½®")
    
    def update_target_batch_size(self, new_target: int):
        """
        æ›´æ–°ç›®æ ‡ç­‰æ•ˆbatch size
        
        Args:
            new_target: æ–°çš„ç›®æ ‡ç­‰æ•ˆbatch size
        """
        old_target = self.target_effective_batch_size
        self.target_effective_batch_size = new_target
        
        # å¦‚æœå·²ç»æœ‰é…ç½®ï¼Œé‡æ–°è®¡ç®—
        if self.current_batch_size is not None:
            self.calculate_accumulation_steps(self.current_batch_size)
        
        print(f"ğŸ”„ ç›®æ ‡ç­‰æ•ˆbatch sizeå·²æ›´æ–°: {old_target} â†’ {new_target}")
    
    def optimize_for_memory_constraint(self, 
                                     available_batch_sizes: List[int],
                                     memory_constraints: List[float]) -> Tuple[int, int]:
        """
        åœ¨å†…å­˜çº¦æŸä¸‹ä¼˜åŒ–é…ç½®
        
        Args:
            available_batch_sizes: å¯ç”¨çš„batch sizeåˆ—è¡¨
            memory_constraints: å¯¹åº”çš„å†…å­˜ä½¿ç”¨ç‡åˆ—è¡¨
            
        Returns:
            (æœ€ä¼˜batch_size, å¯¹åº”çš„ç´¯ç§¯æ­¥æ•°)
        """
        best_config = None
        best_score = -1
        
        for batch_size, memory_usage in zip(available_batch_sizes, memory_constraints):
            # è®¡ç®—è¿™ä¸ªbatch sizeçš„ç´¯ç§¯æ­¥æ•°
            accumulation_steps = max(
                self.min_accumulation_steps,
                min(self.max_accumulation_steps, round(self.target_effective_batch_size / batch_size))
            )
            
            effective_batch = batch_size * accumulation_steps
            
            # è®¡ç®—è¯„åˆ†ï¼ˆè€ƒè™‘ç›®æ ‡è¾¾æˆç‡å’Œå†…å­˜æ•ˆç‡ï¼‰
            target_efficiency = min(1.0, effective_batch / self.target_effective_batch_size)
            memory_efficiency = 1.0 - (memory_usage / 100.0)  # å†…å­˜ä½¿ç”¨è¶Šå°‘è¶Šå¥½
            
            # ç»¼åˆè¯„åˆ†
            score = target_efficiency * 0.7 + memory_efficiency * 0.3
            
            if score > best_score:
                best_score = score
                best_config = (batch_size, accumulation_steps, effective_batch, memory_usage)
        
        if best_config:
            batch_size, accumulation_steps, effective_batch, memory_usage = best_config
            
            print(f"\nğŸ¯ å†…å­˜çº¦æŸä¸‹çš„æœ€ä¼˜é…ç½®:")
            print(f"   batch size: {batch_size}")
            print(f"   ç´¯ç§¯æ­¥æ•°: {accumulation_steps}")
            print(f"   ç­‰æ•ˆbatch: {effective_batch}")
            print(f"   å†…å­˜ä½¿ç”¨: {memory_usage:.1f}%")
            print(f"   ç»¼åˆè¯„åˆ†: {best_score:.3f}")
            
            return batch_size, accumulation_steps
        else:
            print(f"âŒ æ— æ³•æ‰¾åˆ°åˆé€‚çš„é…ç½®")
            return available_batch_sizes[0], self.min_accumulation_steps
    
    def print_status(self, detailed: bool = False):
        """
        æ‰“å°å½“å‰çŠ¶æ€
        
        Args:
            detailed: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        config = self.get_current_config()
        stats = self.get_statistics()
        
        print(f"\nğŸ“Š æ¢¯åº¦ç´¯ç§¯çŠ¶æ€:")
        print(f"   å½“å‰é…ç½®: batch_size={config['current_batch_size']}, "
              f"accumulation={config['accumulation_steps']}, "
              f"effective={config['effective_batch_size']}")
        print(f"   ç›®æ ‡è¾¾æˆ: {config['efficiency_percent']:.1f}%")
        print(f"   æŸå¤±ç¼©æ”¾: {config['loss_scale']:.3f}")
        
        if detailed and stats['total_steps'] > 0:
            print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   æ€»æ­¥æ•°: {stats['total_steps']}")
            print(f"   æ¢¯åº¦æ›´æ–°: {stats['gradient_updates']}")
            print(f"   å½“å‰ç´¯ç§¯: {stats['current_accumulation_count']}/{config['accumulation_steps']}")
            print(f"   æ›´æ–°æ•ˆç‡: {stats['update_efficiency']:.1%}")


class AdaptiveGradientAccumulation(GradientAccumulationManager):
    """
    è‡ªé€‚åº”æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨
    å¯ä»¥æ ¹æ®è®­ç»ƒè¿‡ç¨‹åŠ¨æ€è°ƒæ•´ç´¯ç§¯ç­–ç•¥
    """
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # è‡ªé€‚åº”å‚æ•°
        self.gradient_norm_history = []
        self.loss_history = []
        self.adaptation_enabled = True
        self.adaptation_interval = 100  # æ¯100æ­¥æ£€æŸ¥ä¸€æ¬¡
        
    def record_training_metrics(self, gradient_norm: float, loss: float):
        """
        è®°å½•è®­ç»ƒæŒ‡æ ‡ç”¨äºè‡ªé€‚åº”è°ƒæ•´
        
        Args:
            gradient_norm: æ¢¯åº¦èŒƒæ•°
            loss: æŸå¤±å€¼
        """
        self.gradient_norm_history.append(gradient_norm)
        self.loss_history.append(loss)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.gradient_norm_history) > 1000:
            self.gradient_norm_history = self.gradient_norm_history[-500:]
            self.loss_history = self.loss_history[-500:]
    
    def should_adapt_accumulation(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è°ƒæ•´ç´¯ç§¯ç­–ç•¥
        
        Returns:
            æ˜¯å¦åº”è¯¥è°ƒæ•´
        """
        if not self.adaptation_enabled:
            return False
        
        if len(self.gradient_norm_history) < self.adaptation_interval:
            return False
        
        # æ£€æŸ¥æ¢¯åº¦èŒƒæ•°çš„ç¨³å®šæ€§
        recent_norms = self.gradient_norm_history[-self.adaptation_interval:]
        norm_std = np.std(recent_norms)
        norm_mean = np.mean(recent_norms)
        
        # å¦‚æœæ¢¯åº¦èŒƒæ•°å˜åŒ–å¾ˆå¤§ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç´¯ç§¯ç­–ç•¥
        coefficient_of_variation = norm_std / norm_mean if norm_mean > 0 else 0
        
        return coefficient_of_variation > 0.5  # å˜å¼‚ç³»æ•°å¤§äº0.5æ—¶è€ƒè™‘è°ƒæ•´
    
    def adapt_accumulation_steps(self) -> Optional[int]:
        """
        è‡ªé€‚åº”è°ƒæ•´ç´¯ç§¯æ­¥æ•°
        
        Returns:
            æ–°çš„ç´¯ç§¯æ­¥æ•°ï¼Œå¦‚æœä¸éœ€è¦è°ƒæ•´åˆ™è¿”å›None
        """
        if not self.should_adapt_accumulation():
            return None
        
        # åŸºäºæ¢¯åº¦èŒƒæ•°å†å²è°ƒæ•´ç­–ç•¥
        recent_norms = self.gradient_norm_history[-self.adaptation_interval:]
        norm_mean = np.mean(recent_norms)
        
        # å¦‚æœæ¢¯åº¦èŒƒæ•°å¤ªå°ï¼Œå¢åŠ ç´¯ç§¯æ­¥æ•°
        # å¦‚æœæ¢¯åº¦èŒƒæ•°å¤ªå¤§ï¼Œå‡å°‘ç´¯ç§¯æ­¥æ•°
        if norm_mean < 0.1:
            new_steps = min(self.max_accumulation_steps, self.accumulation_steps + 1)
        elif norm_mean > 2.0:
            new_steps = max(self.min_accumulation_steps, self.accumulation_steps - 1)
        else:
            return None  # ä¸éœ€è¦è°ƒæ•´
        
        if new_steps != self.accumulation_steps:
            old_steps = self.accumulation_steps
            self.accumulation_steps = new_steps
            self.effective_batch_size = self.current_batch_size * new_steps
            
            print(f"ğŸ”„ è‡ªé€‚åº”è°ƒæ•´ç´¯ç§¯æ­¥æ•°: {old_steps} â†’ {new_steps}")
            print(f"   æ¢¯åº¦èŒƒæ•°å‡å€¼: {norm_mean:.3f}")
            print(f"   æ–°ç­‰æ•ˆbatch: {self.effective_batch_size}")
            
            return new_steps
        
        return None


if __name__ == "__main__":
    # æµ‹è¯•æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨
    print("ğŸ§ª æµ‹è¯•æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨...")
    
    # åŸºç¡€ç®¡ç†å™¨æµ‹è¯•
    manager = GradientAccumulationManager(target_effective_batch_size=16)
    
    # æµ‹è¯•ä¸åŒçš„batch sizeé…ç½®
    test_batch_sizes = [4, 8, 12, 16, 24]
    
    print(f"\nğŸ“Š ä¸åŒbatch sizeçš„ç´¯ç§¯é…ç½®:")
    for batch_size in test_batch_sizes:
        accumulation_steps = manager.calculate_accumulation_steps(batch_size)
        config = manager.get_current_config()
        print(f"   batch_size={batch_size}: accumulation={accumulation_steps}, effective={config['effective_batch_size']}")
    
    # æµ‹è¯•æ¢¯åº¦æ›´æ–°é€»è¾‘
    print(f"\nğŸ”¬ æµ‹è¯•æ¢¯åº¦æ›´æ–°é€»è¾‘ (batch_size=8, accumulation=2):")
    manager.calculate_accumulation_steps(8)
    
    for step in range(10):
        should_update = manager.should_update_gradients(step)
        loss_scale = manager.get_loss_scale()
        print(f"   æ­¥éª¤ {step}: æ›´æ–°æ¢¯åº¦={'âœ…' if should_update else 'âŒ'}, æŸå¤±ç¼©æ”¾={loss_scale:.3f}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
    manager.print_status(detailed=True)
    
    # æµ‹è¯•è‡ªé€‚åº”ç®¡ç†å™¨
    print(f"\nğŸ§ª æµ‹è¯•è‡ªé€‚åº”æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨...")
    adaptive_manager = AdaptiveGradientAccumulation(target_effective_batch_size=16)
    adaptive_manager.calculate_accumulation_steps(8)
    
    # æ¨¡æ‹Ÿä¸€äº›è®­ç»ƒæŒ‡æ ‡
    for i in range(150):
        # æ¨¡æ‹Ÿæ¢¯åº¦èŒƒæ•°å’ŒæŸå¤±
        gradient_norm = np.random.normal(1.0, 0.5)
        loss = 3.0 - i * 0.01 + np.random.normal(0, 0.1)
        
        adaptive_manager.record_training_metrics(gradient_norm, loss)
        
        # æ¯50æ­¥æ£€æŸ¥ä¸€æ¬¡è‡ªé€‚åº”
        if i % 50 == 49:
            new_steps = adaptive_manager.adapt_accumulation_steps()
            if new_steps:
                print(f"   æ­¥éª¤ {i}: ç´¯ç§¯æ­¥æ•°è°ƒæ•´ä¸º {new_steps}")
    
    print("âœ… æ¢¯åº¦ç´¯ç§¯ç®¡ç†å™¨æµ‹è¯•å®Œæˆï¼")
