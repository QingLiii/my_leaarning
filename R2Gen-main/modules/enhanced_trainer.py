"""
å¢å¼ºç‰ˆTrainer - é›†æˆWandBç›‘æ§å’Œä¼˜åŒ–åŠŸèƒ½
åŸºäºåŸå§‹trainer.pyï¼Œæ·»åŠ å…¨é¢çš„ç›‘æ§å’Œä¼˜åŒ–åŠŸèƒ½
"""

import os
import time
import torch
import pandas as pd
import numpy as np
from numpy import inf
from .trainer import BaseTrainer
from .wandb_logger import WandBLogger


class EnhancedTrainer(BaseTrainer):
    """
    å¢å¼ºç‰ˆè®­ç»ƒå™¨
    é›†æˆWandBç›‘æ§ã€æ˜¾å­˜ä¼˜åŒ–ã€æ··åˆç²¾åº¦ç­‰åŠŸèƒ½
    """
    
    def __init__(self, model, criterion, metric_ftns, optimizer, args, lr_scheduler, 
                 train_dataloader, val_dataloader, test_dataloader, 
                 wandb_logger=None, enable_wandb=True):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆè®­ç»ƒå™¨
        
        Args:
            model: æ¨¡å‹
            criterion: æŸå¤±å‡½æ•°
            metric_ftns: è¯„ä¼°æŒ‡æ ‡å‡½æ•°
            optimizer: ä¼˜åŒ–å™¨
            args: è®­ç»ƒå‚æ•°
            lr_scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
            train_dataloader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
            test_dataloader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            wandb_logger: WandBæ—¥å¿—è®°å½•å™¨
            enable_wandb: æ˜¯å¦å¯ç”¨WandBç›‘æ§
        """
        super().__init__(model, criterion, metric_ftns, optimizer, args)
        
        self.lr_scheduler = lr_scheduler
        self.train_dataloader = train_dataloader
        self.val_dataloader = val_dataloader
        self.test_dataloader = test_dataloader
        
        # WandBç›‘æ§
        self.enable_wandb = enable_wandb and wandb_logger is not None
        self.wandb_logger = wandb_logger
        
        # ä¼˜åŒ–ç›¸å…³å‚æ•°
        self.gradient_accumulation_steps = getattr(args, 'gradient_accumulation_steps', 1)
        self.mixed_precision = getattr(args, 'mixed_precision', None)  # 'fp16', 'fp8', None
        self.log_interval = getattr(args, 'log_interval', 50)  # æ—¥å¿—è®°å½•é—´éš”
        
        # æ··åˆç²¾åº¦è®¾ç½®
        self.use_amp = self.mixed_precision in ['fp16', 'fp8']
        if self.use_amp:
            self.scaler = torch.amp.GradScaler('cuda')
            print(f"âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ: {self.mixed_precision}")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.batch_times = []
        self.forward_times = []
        self.backward_times = []
        
        # åˆå§‹åŒ–WandB
        if self.enable_wandb:
            self._init_wandb_monitoring()
    
    def _init_wandb_monitoring(self):
        """åˆå§‹åŒ–WandBç›‘æ§"""
        try:
            # å‡†å¤‡é…ç½®ä¿¡æ¯
            config = {
                'model_name': 'R2Gen',
                'dataset': getattr(self.args, 'dataset_name', 'unknown'),
                'batch_size': getattr(self.args, 'batch_size', 'unknown'),
                'learning_rate_ve': getattr(self.args, 'lr_ve', 'unknown'),
                'learning_rate_ed': getattr(self.args, 'lr_ed', 'unknown'),
                'epochs': getattr(self.args, 'epochs', 'unknown'),
                'optimizer': getattr(self.args, 'optim', 'unknown'),
                'lr_scheduler': getattr(self.args, 'lr_scheduler', 'unknown'),
                'mixed_precision': self.mixed_precision,
                'gradient_accumulation_steps': self.gradient_accumulation_steps,
                'seed': getattr(self.args, 'seed', 'unknown'),
                'max_seq_length': getattr(self.args, 'max_seq_length', 'unknown'),
                'threshold': getattr(self.args, 'threshold', 'unknown'),
            }
            
            # ç”Ÿæˆè¿è¡Œåç§°
            precision_suffix = f"_{self.mixed_precision}" if self.mixed_precision else "_fp32"
            run_name = f"R2Gen_{config['dataset']}_bs{config['batch_size']}{precision_suffix}"
            
            # åˆå§‹åŒ–WandBè¿è¡Œ
            self.wandb_logger.init_run(
                config=config,
                run_name=run_name,
                tags=["enhanced_trainer", "optimization", self.mixed_precision or "fp32"]
            )
            
            # è®°å½•æ¨¡å‹ä¿¡æ¯
            self.wandb_logger.log_model_info(self.model)
            
            print("âœ… WandBç›‘æ§åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸ WandBåˆå§‹åŒ–å¤±è´¥: {e}")
            self.enable_wandb = False
    
    def _train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        if self.enable_wandb:
            self.wandb_logger.start_epoch(epoch)
        
        train_loss = 0
        self.model.train()
        
        epoch_start_time = time.time()
        accumulated_loss = 0
        
        for batch_idx, (images_id, images, reports_ids, reports_masks) in enumerate(self.train_dataloader):
            batch_start_time = time.time()
            
            # æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡
            images = images.to(self.device)
            reports_ids = reports_ids.to(self.device)
            reports_masks = reports_masks.to(self.device)
            
            # å‰å‘ä¼ æ’­
            forward_start_time = time.time()
            loss = self._forward_step(images, reports_ids, reports_masks)
            forward_time = time.time() - forward_start_time
            self.forward_times.append(forward_time)
            
            # æ¢¯åº¦ç´¯ç§¯å¤„ç†
            loss = loss / self.gradient_accumulation_steps
            accumulated_loss += loss.item()
            
            # åå‘ä¼ æ’­
            backward_start_time = time.time()
            self._backward_step(loss)
            backward_time = time.time() - backward_start_time
            self.backward_times.append(backward_time)
            
            # å‚æ•°æ›´æ–°ï¼ˆæ¯accumulation_stepsæ­¥æ›´æ–°ä¸€æ¬¡ï¼‰
            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
                self._optimizer_step()
                
                # è®°å½•è®­ç»ƒæŒ‡æ ‡
                if self.enable_wandb:
                    self._log_training_step(epoch, batch_idx, accumulated_loss)
                
                accumulated_loss = 0
            
            train_loss += loss.item() * self.gradient_accumulation_steps
            
            # è®°å½•æ‰¹æ¬¡æ—¶é—´
            batch_time = time.time() - batch_start_time
            self.batch_times.append(batch_time)
            
            # å®šæœŸæ‰“å°è¿›åº¦
            if batch_idx % self.log_interval == 0:
                self._print_progress(epoch, batch_idx, loss.item() * self.gradient_accumulation_steps)
        
        # Epochç»“æŸå¤„ç†
        epoch_time = time.time() - epoch_start_time
        avg_train_loss = train_loss / len(self.train_dataloader)
        
        if self.enable_wandb:
            self._log_epoch_summary(epoch, epoch_time, avg_train_loss)
            self.wandb_logger.end_epoch(epoch)
        
        return {'train_loss': avg_train_loss}
    
    def _forward_step(self, images, reports_ids, reports_masks):
        """å‰å‘ä¼ æ’­æ­¥éª¤"""
        if self.use_amp:
            with torch.amp.autocast('cuda'):
                output = self.model(images, reports_ids, mode='train')
                loss = self.criterion(output, reports_ids, reports_masks)
        else:
            output = self.model(images, reports_ids, mode='train')
            loss = self.criterion(output, reports_ids, reports_masks)

        return loss
    
    def _backward_step(self, loss):
        """åå‘ä¼ æ’­æ­¥éª¤"""
        if self.use_amp:
            self.scaler.scale(loss).backward()
        else:
            loss.backward()
    
    def _optimizer_step(self):
        """ä¼˜åŒ–å™¨æ›´æ–°æ­¥éª¤"""
        if self.use_amp:
            # æ¢¯åº¦è£å‰ª
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_value_(self.model.parameters(), 0.1)
            
            # å‚æ•°æ›´æ–°
            self.scaler.step(self.optimizer)
            self.scaler.update()
        else:
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_value_(self.model.parameters(), 0.1)
            
            # å‚æ•°æ›´æ–°
            self.optimizer.step()
        
        self.optimizer.zero_grad()
    
    def _log_training_step(self, epoch, batch_idx, loss):
        """è®°å½•è®­ç»ƒæ­¥éª¤æŒ‡æ ‡"""
        # è®¡ç®—æ¢¯åº¦èŒƒæ•°
        total_norm = 0
        for p in self.model.parameters():
            if p.grad is not None:
                param_norm = p.grad.data.norm(2)
                total_norm += param_norm.item() ** 2
        total_norm = total_norm ** (1. / 2)
        
        # è·å–å­¦ä¹ ç‡
        lr_ve = self.optimizer.param_groups[0]['lr']
        lr_ed = self.optimizer.param_groups[1]['lr'] if len(self.optimizer.param_groups) > 1 else lr_ve
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        avg_batch_time = np.mean(self.batch_times[-10:]) if self.batch_times else 0
        avg_forward_time = np.mean(self.forward_times[-10:]) if self.forward_times else 0
        avg_backward_time = np.mean(self.backward_times[-10:]) if self.backward_times else 0
        
        # è®°å½•åˆ°WandB
        self.wandb_logger.log_training_metrics(
            epoch=epoch,
            batch_idx=batch_idx,
            loss=loss,
            learning_rate=lr_ve,
            learning_rate_ve=lr_ve,
            learning_rate_ed=lr_ed,
            gradient_norm=total_norm,
            batch_time=avg_batch_time,
            forward_time=avg_forward_time,
            backward_time=avg_backward_time,
            samples_per_sec=self.args.batch_size / avg_batch_time if avg_batch_time > 0 else 0
        )
    
    def _log_epoch_summary(self, epoch, epoch_time, avg_loss):
        """è®°å½•epochæ€»ç»“"""
        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        avg_batch_time = np.mean(self.batch_times) if self.batch_times else 0
        avg_forward_time = np.mean(self.forward_times) if self.forward_times else 0
        avg_backward_time = np.mean(self.backward_times) if self.backward_times else 0
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        self.wandb_logger.log_memory_usage(f"epoch_{epoch}_end")
        
        # æ¸…ç†æ€§èƒ½ç»Ÿè®¡ï¼ˆä¿æŒæœ€è¿‘çš„æ•°æ®ï¼‰
        if len(self.batch_times) > 1000:
            self.batch_times = self.batch_times[-500:]
            self.forward_times = self.forward_times[-500:]
            self.backward_times = self.backward_times[-500:]
    
    def _print_progress(self, epoch, batch_idx, loss):
        """æ‰“å°è®­ç»ƒè¿›åº¦"""
        total_batches = len(self.train_dataloader)
        progress = (batch_idx + 1) / total_batches * 100
        
        avg_batch_time = np.mean(self.batch_times[-10:]) if self.batch_times else 0
        samples_per_sec = self.args.batch_size / avg_batch_time if avg_batch_time > 0 else 0
        
        print(f"Epoch {epoch} [{batch_idx+1}/{total_batches} ({progress:.1f}%)] "
              f"Loss: {loss:.6f} | Speed: {samples_per_sec:.1f} samples/sec")
    
    def _evaluate(self, data_loader, epoch, split='val'):
        """è¯„ä¼°æ¨¡å‹"""
        self.model.eval()
        
        if self.enable_wandb:
            self.wandb_logger.log_memory_usage(f"{split}_start")
        
        with torch.no_grad():
            val_gts, val_res = [], []
            val_loss = 0
            
            for batch_idx, (images_id, images, reports_ids, reports_masks) in enumerate(data_loader):
                images = images.to(self.device)
                reports_ids = reports_ids.to(self.device)
                reports_masks = reports_masks.to(self.device)
                
                # å‰å‘ä¼ æ’­
                if self.use_amp:
                    with torch.amp.autocast('cuda'):
                        output = self.model(images, reports_ids, mode='train')
                        loss = self.criterion(output, reports_ids, reports_masks)
                else:
                    output = self.model(images, reports_ids, mode='train')
                    loss = self.criterion(output, reports_ids, reports_masks)
                
                val_loss += loss.item()
                
                # ç”ŸæˆæŠ¥å‘Šç”¨äºè¯„ä¼°
                generated_ids = self.model(images, mode='sample')

                # åˆ›å»ºtokenizerç”¨äºè§£ç 
                from modules.tokenizers import Tokenizer
                tokenizer = Tokenizer(self.args)

                # è§£ç ç”Ÿæˆçš„æŠ¥å‘Š
                if isinstance(generated_ids, torch.Tensor):
                    # å¦‚æœè¿”å›çš„æ˜¯tensorï¼Œè§£ç æ¯ä¸ªåºåˆ—
                    generated_reports = tokenizer.decode_batch(generated_ids.cpu().numpy())
                else:
                    # å¦‚æœè¿”å›çš„å·²ç»æ˜¯æ–‡æœ¬åˆ—è¡¨
                    generated_reports = generated_ids

                val_res.extend(generated_reports)

                # è§£ç ground truthæŠ¥å‘Š
                gt_reports = tokenizer.decode_batch(reports_ids.cpu().numpy())
                val_gts.extend(gt_reports)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        val_met = self.metric_ftns({i: [gt] for i, gt in enumerate(val_gts)},
                                  {i: [re] for i, re in enumerate(val_res)})
        
        avg_val_loss = val_loss / len(data_loader)
        val_met['loss'] = avg_val_loss
        
        # è®°å½•åˆ°WandB
        if self.enable_wandb:
            if split == 'val':
                self.wandb_logger.log_validation_metrics(epoch, val_met)
            else:
                self.wandb_logger.log_test_metrics(epoch, val_met)
            
            self.wandb_logger.log_memory_usage(f"{split}_end")
        
        return val_met
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯"""
        print("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆè®­ç»ƒ...")
        
        not_improved_count = 0
        validate_every = getattr(self.args, 'validate_every', 1)  # é»˜è®¤æ¯ä¸ªepochéªŒè¯

        for epoch in range(self.start_epoch, self.epochs + 1):
            # è®­ç»ƒä¸€ä¸ªepoch
            result = self._train_epoch(epoch)

            # åªåœ¨æŒ‡å®šçš„epochè¿›è¡ŒéªŒè¯
            if epoch % validate_every == 0 or epoch == self.epochs:
                print(f"ğŸ“Š Epoch {epoch}: å¼€å§‹éªŒè¯...")

                # éªŒè¯
                val_log = self._evaluate(self.val_dataloader, epoch, 'val')
                result.update(**{'val_' + k: v for k, v in val_log.items()})

                # æµ‹è¯•
                test_log = self._evaluate(self.test_dataloader, epoch, 'test')
                result.update(**{'test_' + k: v for k, v in test_log.items()})

                # è®°å½•æœ€ä½³ç»“æœ
                log = {'epoch': epoch}
                log.update(result)
                self._record_best(log)

                # æ‰“å°ç»“æœ
                for key, value in log.items():
                    print('\t{:15s}: {}'.format(str(key), value))
            else:
                # åªè®­ç»ƒï¼Œä¸éªŒè¯
                train_loss = result.get('train_loss', result.get('loss', 0))
                log = {'epoch': epoch, 'train_loss': train_loss}
                print(f"\tEpoch {epoch}: train_loss = {train_loss:.6f}")

            # å­¦ä¹ ç‡è°ƒåº¦
            if self.lr_scheduler is not None:
                self.lr_scheduler.step()
            
            # æ—©åœæ£€æŸ¥ï¼ˆåªåœ¨éªŒè¯epochè¿›è¡Œï¼‰
            best = False
            if (epoch % validate_every == 0 or epoch == self.epochs) and self.mnt_mode != 'off':
                try:
                    improved = (self.mnt_mode == 'min' and log[self.mnt_metric] <= self.mnt_best) or \
                              (self.mnt_mode == 'max' and log[self.mnt_metric] >= self.mnt_best)
                except KeyError:
                    print("Warning: Metric '{}' is not found. Model performance monitoring is disabled.".format(self.mnt_metric))
                    self.mnt_mode = 'off'
                    improved = False

                if improved:
                    self.mnt_best = log[self.mnt_metric]
                    not_improved_count = 0
                    best = True
                else:
                    not_improved_count += 1

                # å¦‚æœä¸æ˜¯æ¯ä¸ªepochéªŒè¯ï¼Œåˆ™ç¦ç”¨æ—©åœ
                if validate_every == 1 and not_improved_count > self.early_stop:
                    print("Validation performance didn't improve for {} epochs. Training stops.".format(self.early_stop))
                    break
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if epoch % self.save_period == 0:
                self._save_checkpoint(epoch, save_best=best)
        
        # è®­ç»ƒç»“æŸ
        self._print_best()
        self._print_best_to_file()
        
        if self.enable_wandb:
            self.wandb_logger.finish()
        
        print("âœ… è®­ç»ƒå®Œæˆï¼")
