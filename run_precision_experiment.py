#!/usr/bin/env python3
"""
å®Œæ•´çš„ç²¾åº¦å¯¹æ¯”å®éªŒè„šæœ¬
è¿è¡ŒFP32 vs FP16 vs FP8çš„15 epochè®­ç»ƒå¯¹æ¯”ï¼ŒåŒ…å«æŠ¥å‘Šè´¨é‡è¯„ä¼°
"""

import os
import sys
import argparse
import torch
import numpy as np
import json
from datetime import datetime
import time

# æ·»åŠ R2Genè·¯å¾„
sys.path.append('R2Gen-main')

from modules.tokenizers import Tokenizer
from modules.dataloaders import R2DataLoader
from modules.metrics import compute_scores
from modules.optimizers import build_optimizer, build_lr_scheduler
from modules.loss import compute_loss
from models.r2gen import R2GenModel
from modules.wandb_logger import WandBLogger
from modules.memory_monitor import MemoryMonitor
from modules.enhanced_trainer import EnhancedTrainer


def create_args(precision='fp32', batch_size=12, epochs=15):
    """åˆ›å»ºè®­ç»ƒå‚æ•°"""
    class Args:
        def __init__(self):
            # æ•°æ®ç›¸å…³
            self.image_dir = 'R2Gen-main/data/iu_xray/images/'
            self.ann_path = 'R2Gen-main/data/iu_xray/annotation.json'
            self.dataset_name = 'iu_xray'
            self.max_seq_length = 60
            self.threshold = 3
            self.num_workers = 2
            self.batch_size = batch_size
            
            # è®­ç»ƒç›¸å…³
            self.epochs = epochs
            self.seed = 9223
            self.n_gpu = 1
            self.save_period = epochs  # åªåœ¨æœ€åä¿å­˜
            self.monitor_mode = 'max'
            self.monitor_metric = 'BLEU_4'
            self.early_stop = epochs + 10  # ç¦ç”¨æ—©åœ
            self.resume = None
            self.validate_every = epochs  # åªåœ¨æœ€åéªŒè¯
            
            # ä¼˜åŒ–å™¨ç›¸å…³
            self.optim = 'Adam'
            self.lr_ve = 5e-5
            self.lr_ed = 1e-4
            self.weight_decay = 0
            self.amsgrad = True
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.lr_scheduler = 'StepLR'
            self.step_size = 50
            self.gamma = 0.1
            
            # æ¨¡å‹ç›¸å…³
            self.d_model = 512
            self.d_ff = 512
            self.d_vf = 2048
            self.num_heads = 8
            self.num_layers = 3
            self.dropout = 0.1
            self.logit_layers = 1
            self.bos_idx = 0
            self.eos_idx = 0
            self.pad_idx = 0
            self.use_bn = 0
            self.drop_prob_lm = 0.5
            
            # è§†è§‰ç‰¹å¾æå–
            self.visual_extractor = 'resnet101'
            self.visual_extractor_pretrained = True
            
            # è®°å¿†æ¨¡å—
            self.rm_num_slots = 3
            self.rm_num_heads = 8
            self.rm_d_model = 512
            
            # é‡‡æ ·ç›¸å…³
            self.sample_method = 'beam_search'
            self.beam_size = 3
            self.temperature = 1.0
            self.sample_n = 1
            self.group_size = 1
            self.output_logsoftmax = 1
            self.decoding_constraint = 0
            self.block_trigrams = 1
            
            # ç²¾åº¦ç›¸å…³
            self.mixed_precision = None if precision == 'fp32' else precision
            
            # ä¿å­˜è·¯å¾„
            self.save_dir = f'results/precision_comparison/{precision}'
            self.record_dir = f'results/precision_comparison/{precision}'
            self.experiment_name = f'R2Gen_{precision}_precision'
            
            # ä¼˜åŒ–ç›¸å…³
            self.gradient_accumulation_steps = 1
            self.log_interval = 50
    
    return Args()


def run_single_precision_training(precision, batch_size, epochs=15):
    """è¿è¡Œå•ä¸ªç²¾åº¦çš„è®­ç»ƒ"""
    print(f"\nğŸš€ å¼€å§‹ {precision.upper()} ç²¾åº¦è®­ç»ƒ...")
    print(f"   Batch Size: {batch_size}")
    print(f"   Epochs: {epochs}")
    print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # åˆ›å»ºå‚æ•°
    args = create_args(precision, batch_size, epochs)
    
    # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
    os.makedirs(args.save_dir, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"   ğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    tokenizer = Tokenizer(args)
    train_dataloader = R2DataLoader(args, tokenizer, split='train', shuffle=True)
    val_dataloader = R2DataLoader(args, tokenizer, split='val', shuffle=False)
    test_dataloader = R2DataLoader(args, tokenizer, split='test', shuffle=False)
    
    print(f"   è®­ç»ƒæ ·æœ¬: {len(train_dataloader.dataset)}")
    print(f"   éªŒè¯æ ·æœ¬: {len(val_dataloader.dataset)}")
    print(f"   æµ‹è¯•æ ·æœ¬: {len(test_dataloader.dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    print(f"   ğŸ—ï¸ åˆ›å»ºæ¨¡å‹...")
    model = R2GenModel(args, tokenizer).cuda()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = build_optimizer(args, model)
    lr_scheduler = build_lr_scheduler(args, optimizer)
    
    # åˆå§‹åŒ–WandB
    print(f"   ğŸ“ˆ åˆå§‹åŒ–WandBç›‘æ§...")
    wandb_logger = WandBLogger(project_name="R2Gen-Precision-Comparison")
    
    wandb_config = {
        'precision': precision,
        'mixed_precision': args.mixed_precision,
        'batch_size': batch_size,
        'epochs': epochs,
        'learning_rate_ve': args.lr_ve,
        'learning_rate_ed': args.lr_ed,
        'model': 'R2Gen',
        'dataset': args.dataset_name,
        'experiment_type': 'precision_comparison',
        'optimizer': args.optim,
        'scheduler': args.lr_scheduler
    }
    
    run_name = f"R2Gen_{precision}_bs{batch_size}_ep{epochs}"
    wandb_logger.init_run(wandb_config, run_name=run_name)
    
    # åˆ›å»ºå¢å¼ºç‰ˆtrainer
    print(f"   ğŸ¯ åˆ›å»ºè®­ç»ƒå™¨...")
    trainer = EnhancedTrainer(
        model=model,
        criterion=compute_loss,
        metric_ftns=compute_scores,
        optimizer=optimizer,
        args=args,
        lr_scheduler=lr_scheduler,
        train_dataloader=train_dataloader,
        val_dataloader=val_dataloader,
        test_dataloader=test_dataloader,
        wandb_logger=wandb_logger,
        enable_wandb=True
    )
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    try:
        # å¼€å§‹è®­ç»ƒ
        print(f"   ğŸƒ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        
        training_success = True
        print(f"   âœ… {precision.upper()} è®­ç»ƒæˆåŠŸå®Œæˆ!")
        
    except Exception as e:
        print(f"   âŒ {precision.upper()} è®­ç»ƒå¤±è´¥: {e}")
        training_success = False
        import traceback
        traceback.print_exc()
    
    # è®°å½•ç»“æŸæ—¶é—´
    end_time = time.time()
    total_time = end_time - start_time
    
    # ç»“æŸWandBè¿è¡Œ
    wandb_logger.finish()
    
    # è¿”å›ç»“æœ
    result = {
        'precision': precision,
        'batch_size': batch_size,
        'epochs': epochs,
        'success': training_success,
        'total_time_seconds': total_time,
        'total_time_hours': total_time / 3600,
        'start_time': datetime.fromtimestamp(start_time).isoformat(),
        'end_time': datetime.fromtimestamp(end_time).isoformat(),
        'model_path': os.path.join(args.save_dir, 'model_best.pth') if training_success else None,
        'wandb_run_name': run_name
    }
    
    print(f"   â±ï¸ è®­ç»ƒè€—æ—¶: {total_time/3600:.2f} å°æ—¶")
    
    return result


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='R2Genç²¾åº¦å¯¹æ¯”å®éªŒ')
    parser.add_argument('--precision', type=str, choices=['fp32', 'fp16', 'fp8', 'all'], 
                       default='all', help='è¿è¡Œç‰¹å®šç²¾åº¦å®éªŒ')
    parser.add_argument('--epochs', type=int, default=15, help='è®­ç»ƒepochsæ•°')
    parser.add_argument('--fp32-batch-size', type=int, default=12, help='FP32 batch size')
    parser.add_argument('--fp16-batch-size', type=int, default=24, help='FP16 batch size')
    parser.add_argument('--fp8-batch-size', type=int, default=32, help='FP8 batch size')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ R2Genç²¾åº¦å¯¹æ¯”å®éªŒ")
    print(f"   ç²¾åº¦èŒƒå›´: {args.precision}")
    print(f"   è®­ç»ƒepochs: {args.epochs}")
    print(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ç²¾åº¦é…ç½®
    precision_configs = {
        'fp32': {'batch_size': args.fp32_batch_size, 'description': 'Full Precision (FP32)'},
        'fp16': {'batch_size': args.fp16_batch_size, 'description': 'Half Precision (FP16)'},
        'fp8': {'batch_size': args.fp8_batch_size, 'description': 'FP8 Precision (experimental)'}
    }
    
    # ç¡®å®šè¦è¿è¡Œçš„ç²¾åº¦
    if args.precision == 'all':
        precisions_to_run = ['fp32', 'fp16', 'fp8']
    else:
        precisions_to_run = [args.precision]
    
    print(f"   å°†è¿è¡Œç²¾åº¦: {precisions_to_run}")
    
    # è¿è¡Œå®éªŒ
    all_results = {}
    
    for precision in precisions_to_run:
        config = precision_configs[precision]
        print(f"\n{'='*60}")
        print(f"å¼€å§‹ {precision.upper()} å®éªŒ")
        print(f"æè¿°: {config['description']}")
        print(f"{'='*60}")
        
        try:
            result = run_single_precision_training(
                precision=precision,
                batch_size=config['batch_size'],
                epochs=args.epochs
            )
            all_results[precision] = result
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            result_file = f"precision_results_{timestamp}.json"
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, indent=2, ensure_ascii=False)
            
            print(f"   ğŸ’¾ ç»“æœå·²ä¿å­˜: {result_file}")
            
        except Exception as e:
            print(f"   âŒ {precision.upper()} å®éªŒå¤±è´¥: {e}")
            all_results[precision] = {
                'precision': precision,
                'success': False,
                'error': str(e)
            }
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ç²¾åº¦å¯¹æ¯”å®éªŒå®Œæˆ!")
    print(f"{'='*60}")
    
    successful_experiments = {k: v for k, v in all_results.items() if v.get('success', False)}
    
    if successful_experiments:
        print(f"âœ… æˆåŠŸå®éªŒ: {len(successful_experiments)}/{len(all_results)}")
        print(f"\nâ±ï¸ è®­ç»ƒæ—¶é—´å¯¹æ¯”:")
        
        for precision, result in successful_experiments.items():
            print(f"   {precision.upper()}: {result['total_time_hours']:.2f} å°æ—¶")
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        if 'fp32' in successful_experiments:
            fp32_time = successful_experiments['fp32']['total_time_hours']
            print(f"\nğŸš€ ç›¸å¯¹FP32çš„åŠ é€Ÿæ¯”:")
            
            for precision, result in successful_experiments.items():
                if precision != 'fp32':
                    speedup = fp32_time / result['total_time_hours']
                    print(f"   {precision.upper()}: {speedup:.2f}x")
        
        print(f"\nğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®:")
        for precision, result in successful_experiments.items():
            if result.get('model_path'):
                print(f"   {precision.upper()}: {result['model_path']}")
    else:
        print(f"âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒ")
    
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: è¿è¡ŒæŠ¥å‘Šè´¨é‡è¯„ä¼°")
    print(f"   ä½¿ç”¨å‘½ä»¤: python evaluate_report_quality.py")


if __name__ == "__main__":
    main()
