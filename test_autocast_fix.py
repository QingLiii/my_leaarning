#!/usr/bin/env python3
"""
æµ‹è¯•æ–°çš„torch.amp.autocastç”¨æ³•æ˜¯å¦æ­£å¸¸å·¥ä½œ
éªŒè¯FutureWarningä¿®å¤æ˜¯å¦æˆåŠŸ
"""

import torch
import warnings
import sys

def test_new_autocast():
    """æµ‹è¯•æ–°çš„autocastç”¨æ³•"""
    print("ğŸ§ª æµ‹è¯•æ–°çš„torch.amp.autocastç”¨æ³•...")
    
    # æ•è·è­¦å‘Š
    with warnings.catch_warnings(record=True) as w:
        warnings.simplefilter("always")
        
        # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
        if not torch.cuda.is_available():
            print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return False
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        device = 'cuda'
        x = torch.randn(2, 3, 224, 224, device=device)
        
        # æµ‹è¯•æ–°çš„autocastç”¨æ³•
        try:
            with torch.amp.autocast('cuda'):
                y = x * 2.0
                z = torch.sum(y)
            
            print("âœ… æ–°çš„torch.amp.autocast('cuda')ç”¨æ³•æ­£å¸¸å·¥ä½œ")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰FutureWarning
            future_warnings = [warning for warning in w if issubclass(warning.category, FutureWarning)]
            autocast_warnings = [warning for warning in future_warnings if 'autocast' in str(warning.message)]
            
            if autocast_warnings:
                print("âŒ ä»ç„¶å­˜åœ¨autocastç›¸å…³çš„FutureWarning:")
                for warning in autocast_warnings:
                    print(f"   {warning.message}")
                return False
            else:
                print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°autocastç›¸å…³çš„FutureWarning")
                return True
                
        except Exception as e:
            print(f"âŒ æ–°çš„autocastç”¨æ³•å‡ºé”™: {e}")
            return False

def test_new_gradscaler():
    """æµ‹è¯•æ–°çš„GradScalerç”¨æ³•"""
    print("\nğŸ§ª æµ‹è¯•æ–°çš„torch.amp.GradScalerç”¨æ³•...")
    
    # æ•è·è­¦å‘Š
    with warnings.catch_warnings(record=True) as w:
        warnings.simplefilter("always")
        
        try:
            # æµ‹è¯•æ–°çš„GradScalerç”¨æ³•
            scaler = torch.amp.GradScaler('cuda')
            print("âœ… æ–°çš„torch.amp.GradScaler('cuda')ç”¨æ³•æ­£å¸¸å·¥ä½œ")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰FutureWarning
            future_warnings = [warning for warning in w if issubclass(warning.category, FutureWarning)]
            gradscaler_warnings = [warning for warning in future_warnings if 'GradScaler' in str(warning.message)]
            
            if gradscaler_warnings:
                print("âŒ ä»ç„¶å­˜åœ¨GradScalerç›¸å…³çš„FutureWarning:")
                for warning in gradscaler_warnings:
                    print(f"   {warning.message}")
                return False
            else:
                print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°GradScalerç›¸å…³çš„FutureWarning")
                return True
                
        except Exception as e:
            print(f"âŒ æ–°çš„GradScalerç”¨æ³•å‡ºé”™: {e}")
            return False

def test_old_autocast_warning():
    """æµ‹è¯•æ—§çš„autocastç”¨æ³•æ˜¯å¦ä¼šäº§ç”Ÿè­¦å‘Š"""
    print("\nğŸ§ª æµ‹è¯•æ—§çš„torch.cuda.amp.autocastç”¨æ³•æ˜¯å¦äº§ç”Ÿè­¦å‘Š...")
    
    # æ•è·è­¦å‘Š
    with warnings.catch_warnings(record=True) as w:
        warnings.simplefilter("always")
        
        if not torch.cuda.is_available():
            print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
            return True
        
        try:
            device = 'cuda'
            x = torch.randn(2, 3, 224, 224, device=device)
            
            # ä½¿ç”¨æ—§çš„autocastç”¨æ³•
            with torch.cuda.amp.autocast():
                y = x * 2.0
                z = torch.sum(y)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰FutureWarning
            future_warnings = [warning for warning in w if issubclass(warning.category, FutureWarning)]
            autocast_warnings = [warning for warning in future_warnings if 'autocast' in str(warning.message)]
            
            if autocast_warnings:
                print("âœ… æ—§çš„ç”¨æ³•ç¡®å®äº§ç”Ÿäº†FutureWarning:")
                for warning in autocast_warnings:
                    print(f"   {warning.message}")
                return True
            else:
                print("âš ï¸ æ—§çš„ç”¨æ³•æ²¡æœ‰äº§ç”Ÿé¢„æœŸçš„FutureWarning")
                return False
                
        except Exception as e:
            print(f"âŒ æ—§çš„autocastç”¨æ³•å‡ºé”™: {e}")
            return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ”§ FutureWarningä¿®å¤éªŒè¯æµ‹è¯•")
    print("=" * 60)
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
    
    print("\n" + "=" * 60)
    
    # è¿è¡Œæµ‹è¯•
    test1_passed = test_new_autocast()
    test2_passed = test_new_gradscaler()
    test3_passed = test_old_autocast_warning()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 60)
    
    print(f"âœ… æ–°autocastç”¨æ³•æµ‹è¯•: {'é€šè¿‡' if test1_passed else 'å¤±è´¥'}")
    print(f"âœ… æ–°GradScalerç”¨æ³•æµ‹è¯•: {'é€šè¿‡' if test2_passed else 'å¤±è´¥'}")
    print(f"âœ… æ—§ç”¨æ³•è­¦å‘ŠéªŒè¯: {'é€šè¿‡' if test3_passed else 'å¤±è´¥'}")
    
    all_passed = test1_passed and test2_passed and test3_passed
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼FutureWarningä¿®å¤æˆåŠŸï¼")
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¿®å¤æƒ…å†µ")
        return 1

if __name__ == "__main__":
    sys.exit(main())
