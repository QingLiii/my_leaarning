# FutureWarningä¿®å¤æ€»ç»“

## é—®é¢˜æè¿°
ä»£ç ä¸­å­˜åœ¨PyTorchçš„FutureWarningè­¦å‘Šï¼š
```
FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
```

## ä¿®å¤å†…å®¹

### 1. æ ¸å¿ƒè®­ç»ƒæ¨¡å—ä¿®å¤

#### `R2Gen-main/modules/enhanced_trainer.py`
- **ç¬¬60è¡Œ**: `torch.cuda.amp.GradScaler()` â†’ `torch.amp.GradScaler('cuda')`
- **ç¬¬180è¡Œ**: `torch.cuda.amp.autocast()` â†’ `torch.amp.autocast('cuda')`
- **ç¬¬294è¡Œ**: `torch.cuda.amp.autocast()` â†’ `torch.amp.autocast('cuda')`

#### `R2Gen-main/modules/batch_size_optimizer.py`
- **ç¬¬122è¡Œ**: `torch.cuda.amp.autocast()` â†’ `torch.amp.autocast('cuda')`
- **ç¬¬128è¡Œ**: `torch.cuda.amp.autocast()` â†’ `torch.amp.autocast('cuda')`

#### `R2Gen-main/test_memory_optimization.py`
- **ç¬¬112è¡Œ**: `torch.cuda.amp.autocast()` â†’ `torch.amp.autocast('cuda')`

#### `R2Gen-main/modules/report_quality_evaluator.py`
- **ç¬¬103è¡Œ**: `torch.cuda.amp.autocast()` â†’ `torch.amp.autocast('cuda')`

### 2. æ–‡æ¡£ä¿®å¤

#### `R2Gen_ä¼˜åŒ–æ–¹æ¡ˆ.md`
- **ç¬¬72è¡Œ**: `torch.cuda.amp.GradScaler()` â†’ `torch.amp.GradScaler('cuda')`
- **ç¬¬174è¡Œ**: `from torch.cuda.amp import autocast, GradScaler` â†’ `from torch.amp import autocast, GradScaler`

## ä¿®å¤éªŒè¯

### æµ‹è¯•è„šæœ¬
åˆ›å»ºäº† `test_autocast_fix.py` éªŒè¯ä¿®å¤æ•ˆæœï¼š

```python
# æ–°ç”¨æ³•æµ‹è¯•
with torch.amp.autocast('cuda'):
    # å‰å‘ä¼ æ’­ä»£ç 
    pass

scaler = torch.amp.GradScaler('cuda')
```

### æµ‹è¯•ç»“æœ
```
âœ… æ–°autocastç”¨æ³•æµ‹è¯•: é€šè¿‡
âœ… æ–°GradScalerç”¨æ³•æµ‹è¯•: é€šè¿‡
âœ… æ—§ç”¨æ³•è­¦å‘ŠéªŒè¯: é€šè¿‡
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼FutureWarningä¿®å¤æˆåŠŸï¼
```

## å½±å“çš„åŠŸèƒ½æ¨¡å—

1. **æ··åˆç²¾åº¦è®­ç»ƒ** (`EnhancedTrainer`)
   - FP16/FP8è®­ç»ƒæ¨¡å¼
   - æ¢¯åº¦ç¼©æ”¾å’Œç´¯ç§¯

2. **Batch Sizeä¼˜åŒ–** (`BatchSizeOptimizer`)
   - ä¸åŒç²¾åº¦æ¨¡å¼çš„æ˜¾å­˜æµ‹è¯•
   - è‡ªåŠ¨batch sizeè°ƒä¼˜

3. **æ˜¾å­˜ä¼˜åŒ–æµ‹è¯•** (`test_memory_optimization.py`)
   - æ˜¾å­˜ä½¿ç”¨ç‡ç›‘æ§
   - OOMä¿æŠ¤æœºåˆ¶

4. **æŠ¥å‘Šè´¨é‡è¯„ä¼°** (`ReportQualityEvaluator`)
   - æ¨¡å‹æ¨ç†æ—¶çš„æ··åˆç²¾åº¦æ”¯æŒ

## å…¼å®¹æ€§è¯´æ˜

- **PyTorchç‰ˆæœ¬è¦æ±‚**: æ”¯æŒ `torch.amp` æ¨¡å—çš„ç‰ˆæœ¬ (â‰¥1.6.0)
- **å‘åå…¼å®¹**: æ—§çš„ `torch.cuda.amp` ç”¨æ³•ä»ç„¶å¯ç”¨ï¼Œä½†ä¼šäº§ç”Ÿè­¦å‘Š
- **åŠŸèƒ½å®Œå…¨ç­‰ä»·**: æ–°ç”¨æ³•ä¸æ—§ç”¨æ³•åŠŸèƒ½å®Œå…¨ç›¸åŒï¼Œåªæ˜¯APIæ›´æ–°

## åç»­å»ºè®®

1. **å®šæœŸæ£€æŸ¥**: å®šæœŸè¿è¡Œ `test_autocast_fix.py` ç¡®ä¿æ²¡æœ‰æ–°çš„FutureWarning
2. **ä»£ç å®¡æŸ¥**: åœ¨æ·»åŠ æ–°çš„æ··åˆç²¾åº¦ä»£ç æ—¶ï¼Œä½¿ç”¨æ–°çš„APIæ ¼å¼
3. **ä¾èµ–æ›´æ–°**: ä¿æŒPyTorchç‰ˆæœ¬æ›´æ–°ï¼Œå…³æ³¨æ–°çš„APIå˜åŒ–

## ä¿®å¤å‰åå¯¹æ¯”

### ä¿®å¤å‰
```python
# ä¼šäº§ç”ŸFutureWarning
with torch.cuda.amp.autocast():
    output = model(input)

scaler = torch.cuda.amp.GradScaler()
```

### ä¿®å¤å
```python
# æ— è­¦å‘Šï¼Œæ¨èç”¨æ³•
with torch.amp.autocast('cuda'):
    output = model(input)

scaler = torch.amp.GradScaler('cuda')
```

## æ€»ç»“

âœ… **ä¿®å¤å®Œæˆ**: æ‰€æœ‰ä»£ç ä¸­çš„ `torch.cuda.amp.autocast` å·²æ›´æ–°ä¸º `torch.amp.autocast('cuda')`
âœ… **ä¿®å¤å®Œæˆ**: æ‰€æœ‰ä»£ç ä¸­çš„ `torch.cuda.amp.GradScaler` å·²æ›´æ–°ä¸º `torch.amp.GradScaler('cuda')`
âœ… **æµ‹è¯•é€šè¿‡**: éªŒè¯è„šæœ¬ç¡®è®¤ä¿®å¤æˆåŠŸï¼Œæ— FutureWarning
âœ… **åŠŸèƒ½æ­£å¸¸**: æ‰€æœ‰æ··åˆç²¾åº¦è®­ç»ƒåŠŸèƒ½æ­£å¸¸å·¥ä½œ
âœ… **æ–‡æ¡£æ›´æ–°**: ç›¸å…³æ–‡æ¡£å·²åŒæ­¥æ›´æ–°

ç°åœ¨ä»£ç ç¬¦åˆPyTorchæœ€æ–°æ ‡å‡†ï¼Œä¸å†äº§ç”ŸFutureWarningè­¦å‘Šã€‚
