#!/usr/bin/env python3
"""
è¯Šæ–­BatchNormç»´åº¦ä¸åŒ¹é…é—®é¢˜
å®šä½å…·ä½“çš„é”™è¯¯è§¦å‘ä½ç½®å’ŒåŸå› 
"""

import sys
import torch
import torch.nn as nn
import traceback
from contextlib import contextmanager

sys.path.append('R2Gen-main')

@contextmanager
def debug_autocast(enabled=True, dtype=torch.float16):
    """è°ƒè¯•ç‰ˆæœ¬çš„autocastï¼Œæ•è·è¯¦ç»†é”™è¯¯ä¿¡æ¯"""
    if enabled:
        print(f"ğŸ” å¼€å§‹autocastè°ƒè¯• (dtype={dtype})")
        try:
            with torch.autocast('cuda', dtype=dtype):
                yield
        except Exception as e:
            print(f"âŒ autocasté”™è¯¯: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
            traceback.print_exc()
            raise
    else:
        yield

def test_visual_extractor():
    """æµ‹è¯•è§†è§‰ç‰¹å¾æå–å™¨çš„æ··åˆç²¾åº¦å…¼å®¹æ€§"""
    print("\nğŸ” æµ‹è¯•Visual Extractor...")
    
    try:
        from modules.visual_extractor import VisualExtractor
        import argparse
        
        # åˆ›å»ºæµ‹è¯•å‚æ•°
        args = argparse.Namespace()
        args.visual_extractor = 'resnet101'
        args.visual_extractor_pretrained = True
        args.d_vf = 2048
        
        # åˆ›å»ºæ¨¡å‹
        model = VisualExtractor(args).cuda()
        print(f"âœ… Visual Extractoråˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•FP32
        print("ğŸ§ª æµ‹è¯•FP32...")
        x = torch.randn(2, 3, 224, 224).cuda()
        with torch.no_grad():
            att_feats, fc_feats = model(x)
            print(f"âœ… FP32æˆåŠŸ: att_feats={att_feats.shape}, fc_feats={fc_feats.shape}")
        
        # æµ‹è¯•FP16
        print("ğŸ§ª æµ‹è¯•FP16...")
        try:
            with debug_autocast(True, torch.float16):
                with torch.no_grad():
                    att_feats, fc_feats = model(x)
                    print(f"âœ… FP16æˆåŠŸ: att_feats={att_feats.shape}, fc_feats={fc_feats.shape}")
        except Exception as e:
            print(f"âŒ FP16å¤±è´¥: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ Visual Extractoræµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True

def test_encoder_decoder():
    """æµ‹è¯•ç¼–ç å™¨è§£ç å™¨çš„æ··åˆç²¾åº¦å…¼å®¹æ€§"""
    print("\nğŸ” æµ‹è¯•Encoder Decoder...")
    
    try:
        from modules.encoder_decoder import EncoderDecoder
        from modules.tokenizers import Tokenizer
        import argparse
        
        # åˆ›å»ºæµ‹è¯•å‚æ•°
        args = argparse.Namespace()
        args.ann_path = 'datasets/iu_xray/annotation.json'
        args.threshold = 3
        args.dataset_name = 'iu_xray'
        args.d_model = 512
        args.d_ff = 512
        args.d_vf = 2048
        args.num_heads = 8
        args.num_layers = 3
        args.dropout = 0.1
        args.logit_layers = 1
        args.bos_idx = 0
        args.eos_idx = 0
        args.pad_idx = 0
        args.use_bn = True
        args.rm_num_slots = 3
        args.rm_num_heads = 8
        args.rm_d_model = 512
        args.sample_method = 'beam_search'
        args.beam_size = 3
        args.temperature = 1.0
        args.sample_n = 1
        args.drop_prob_lm = 0.5
        
        # åˆ›å»ºtokenizerå’Œæ¨¡å‹
        tokenizer = Tokenizer(args)
        model = EncoderDecoder(args, tokenizer).cuda()
        print(f"âœ… Encoder Decoderåˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 2
        fc_feats = torch.randn(batch_size, 2048).cuda()
        att_feats = torch.randn(batch_size, 49, 2048).cuda()
        targets = torch.randint(1, 100, (batch_size, 20)).cuda()
        
        # æµ‹è¯•FP32
        print("ğŸ§ª æµ‹è¯•FP32...")
        with torch.no_grad():
            output = model(fc_feats, att_feats, targets, mode='forward')
            print(f"âœ… FP32æˆåŠŸ: output shape={output.shape}")
        
        # æµ‹è¯•FP16
        print("ğŸ§ª æµ‹è¯•FP16...")
        try:
            with debug_autocast(True, torch.float16):
                with torch.no_grad():
                    output = model(fc_feats, att_feats, targets, mode='forward')
                    print(f"âœ… FP16æˆåŠŸ: output shape={output.shape}")
        except Exception as e:
            print(f"âŒ FP16å¤±è´¥: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ Encoder Decoderæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True

def test_full_model():
    """æµ‹è¯•å®Œæ•´R2Genæ¨¡å‹çš„æ··åˆç²¾åº¦å…¼å®¹æ€§"""
    print("\nğŸ” æµ‹è¯•å®Œæ•´R2Genæ¨¡å‹...")
    
    try:
        from models.r2gen import R2GenModel
        from modules.tokenizers import Tokenizer
        import argparse
        
        # åˆ›å»ºæµ‹è¯•å‚æ•°
        args = argparse.Namespace()
        args.ann_path = 'datasets/iu_xray/annotation.json'
        args.threshold = 3
        args.dataset_name = 'iu_xray'
        args.image_dir = 'datasets/iu_xray/images/'
        args.max_seq_length = 60
        args.d_model = 512
        args.d_ff = 512
        args.d_vf = 2048
        args.num_heads = 8
        args.num_layers = 3
        args.dropout = 0.1
        args.logit_layers = 1
        args.bos_idx = 0
        args.eos_idx = 0
        args.pad_idx = 0
        args.use_bn = True
        args.rm_num_slots = 3
        args.rm_num_heads = 8
        args.rm_d_model = 512
        args.visual_extractor = 'resnet101'
        args.visual_extractor_pretrained = True
        args.sample_method = 'beam_search'
        args.beam_size = 3
        args.temperature = 1.0
        args.sample_n = 1
        args.drop_prob_lm = 0.5
        
        # åˆ›å»ºtokenizerå’Œæ¨¡å‹
        tokenizer = Tokenizer(args)
        model = R2GenModel(args, tokenizer).cuda()
        print(f"âœ… R2Genæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ® (IU X-Rayæ ¼å¼: 2å¼ å›¾ç‰‡)
        batch_size = 2
        images = torch.randn(batch_size, 2, 3, 224, 224).cuda()
        targets = torch.randint(1, 100, (batch_size, 20)).cuda()
        
        # æµ‹è¯•FP32
        print("ğŸ§ª æµ‹è¯•FP32...")
        with torch.no_grad():
            output = model(images, targets, mode='train')
            print(f"âœ… FP32æˆåŠŸ: output shape={output.shape}")
        
        # æµ‹è¯•FP16
        print("ğŸ§ª æµ‹è¯•FP16...")
        try:
            with debug_autocast(True, torch.float16):
                with torch.no_grad():
                    output = model(images, targets, mode='train')
                    print(f"âœ… FP16æˆåŠŸ: output shape={output.shape}")
        except Exception as e:
            print(f"âŒ FP16å¤±è´¥: {e}")
            
            # è¯¦ç»†åˆ†æé”™è¯¯
            if "running_mean should contain" in str(e):
                print("ğŸ” æ£€æµ‹åˆ°BatchNormç»´åº¦ä¸åŒ¹é…é”™è¯¯")
                print("è¿™é€šå¸¸æ˜¯ç”±äºé¢„è®­ç»ƒæƒé‡ä¸å½“å‰æ¨¡å‹ç»“æ„ä¸åŒ¹é…å¯¼è‡´çš„")
            elif "bias type" in str(e):
                print("ğŸ” æ£€æµ‹åˆ°ç±»å‹ä¸åŒ¹é…é”™è¯¯")
                print("è¿™é€šå¸¸æ˜¯ç”±äºautocastèŒƒå›´è®¾ç½®ä¸å½“å¯¼è‡´çš„")
            
            return False
            
    except Exception as e:
        print(f"âŒ å®Œæ•´æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False
    
    return True

def analyze_batchnorm_layers():
    """åˆ†ææ¨¡å‹ä¸­çš„BatchNormå±‚"""
    print("\nğŸ” åˆ†æBatchNormå±‚...")
    
    try:
        from models.r2gen import R2GenModel
        from modules.tokenizers import Tokenizer
        import argparse
        
        # åˆ›å»ºæµ‹è¯•å‚æ•°
        args = argparse.Namespace()
        args.ann_path = 'datasets/iu_xray/annotation.json'
        args.threshold = 3
        args.dataset_name = 'iu_xray'
        args.image_dir = 'datasets/iu_xray/images/'
        args.max_seq_length = 60
        args.d_model = 512
        args.d_ff = 512
        args.d_vf = 2048
        args.num_heads = 8
        args.num_layers = 3
        args.dropout = 0.1
        args.logit_layers = 1
        args.bos_idx = 0
        args.eos_idx = 0
        args.pad_idx = 0
        args.use_bn = True
        args.rm_num_slots = 3
        args.rm_num_heads = 8
        args.rm_d_model = 512
        args.visual_extractor = 'resnet101'
        args.visual_extractor_pretrained = True
        args.sample_method = 'beam_search'
        args.beam_size = 3
        args.temperature = 1.0
        args.sample_n = 1
        args.drop_prob_lm = 0.5
        
        tokenizer = Tokenizer(args)
        model = R2GenModel(args, tokenizer)
        
        print("ğŸ“Š BatchNormå±‚ç»Ÿè®¡:")
        bn_count = 0
        for name, module in model.named_modules():
            if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)):
                print(f"  {name}: {type(module).__name__}, num_features={module.num_features}")
                print(f"    running_mean shape: {module.running_mean.shape}")
                print(f"    running_var shape: {module.running_var.shape}")
                bn_count += 1
        
        print(f"æ€»è®¡BatchNormå±‚æ•°: {bn_count}")
        
    except Exception as e:
        print(f"âŒ BatchNormåˆ†æå¤±è´¥: {e}")
        traceback.print_exc()

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    print("ğŸš€ å¼€å§‹BatchNormå…¼å®¹æ€§é—®é¢˜è¯Šæ–­...")
    
    # åˆ†æBatchNormå±‚
    analyze_batchnorm_layers()
    
    # é€æ­¥æµ‹è¯•å„ä¸ªç»„ä»¶
    ve_success = test_visual_extractor()
    ed_success = test_encoder_decoder()
    full_success = test_full_model()
    
    print(f"\nğŸ“‹ è¯Šæ–­ç»“æœæ€»ç»“:")
    print(f"  Visual Extractor FP16: {'âœ… æˆåŠŸ' if ve_success else 'âŒ å¤±è´¥'}")
    print(f"  Encoder Decoder FP16: {'âœ… æˆåŠŸ' if ed_success else 'âŒ å¤±è´¥'}")
    print(f"  å®Œæ•´æ¨¡å‹ FP16: {'âœ… æˆåŠŸ' if full_success else 'âŒ å¤±è´¥'}")
    
    if not any([ve_success, ed_success, full_success]):
        print("\nğŸ”§ å»ºè®®çš„ä¿®å¤ç­–ç•¥:")
        print("1. æ£€æŸ¥é¢„è®­ç»ƒæƒé‡çš„å…¼å®¹æ€§")
        print("2. è€ƒè™‘ä½¿ç”¨LayerNormæ›¿æ¢BatchNorm")
        print("3. è°ƒæ•´autocastçš„ä½œç”¨èŒƒå›´")
        print("4. ä½¿ç”¨æ›´ç²¾ç¡®çš„ç±»å‹è½¬æ¢")

if __name__ == "__main__":
    main()
